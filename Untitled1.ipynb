{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0599ca8-7be5-440a-9ec1-cdc9a25ea68f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Service\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def scrape_dynamic_content(url):\n",
    "    # Set up Selenium\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    service = Service('path/to/chromedriver')  # Replace 'path/to/chromedriver' with the path to your chromedriver\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for dynamic content to load (you may need to adjust the wait time)\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    # Extract elements with dynamic content\n",
    "    headlines = driver.find_elements(By.XPATH, '//div[@class=\"dynamic-content\"]/h2')\n",
    "    contents = driver.find_elements(By.XPATH, '//div[@class=\"dynamic-content\"]/p')\n",
    "\n",
    "    # Extract text from elements\n",
    "    scraped_data = []\n",
    "    for headline, content in zip(headlines, contents):\n",
    "        scraped_data.append({\n",
    "            'headline': headline.text.strip(),\n",
    "            'content': content.text.strip()\n",
    "        })\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    return scraped_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://example.com'  # Replace with the URL of the website you want to scrape\n",
    "    scraped_data = scrape_dynamic_content(url)\n",
    "    for idx, data in enumerate(scraped_data, start=1):\n",
    "        print(f\"Article {idx}:\")\n",
    "        print(f\"Headline: {data['headline']}\")\n",
    "        print(f\"Content: {data['content']}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a74259-56b5-49e6-b811-cfcd7c79cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training the models with ATOM-GBP and saving\n",
    "\n",
    "# import joblib\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from xgboost import XGBRegressor\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# def evaluate_models_ATOM(selected_data, chosen_model='all', save_models=True):\n",
    "#     # Making a copy of the slice to ensure it's a separate object\n",
    "#     selected_data = selected_data.copy()\n",
    "\n",
    "#     for lag in range(1, 4):  # Adding lagged features for 1 to 3 days\n",
    "#         selected_data.loc[:, f'ATOM-GBP_lag_{lag}'] = selected_data['ATOM-GBP'].shift(lag)\n",
    "\n",
    "#     # Dropping rows with NaN values created due to shifting\n",
    "#     selected_data.dropna(inplace=True)\n",
    "\n",
    "#     # Features will be the lagged values, and the target will be the current BTC-GBP price\n",
    "#     features = [f'ATOM-GBP_lag_{lag}' for lag in range(1, 4)]\n",
    "#     X = selected_data[features]\n",
    "#     y = selected_data['ATOM-GBP']\n",
    "\n",
    "#     # Splitting the dataset into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize and train the models\n",
    "#     models = {\n",
    "#         'GRADIENT BOOSTING': GradientBoostingRegressor(),\n",
    "#         'SVR': SVR(),\n",
    "#         'XGBOOST': XGBRegressor(),\n",
    "#         'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "#     }\n",
    "\n",
    "#     if chosen_model.lower() == 'all':\n",
    "#         chosen_models = models.keys()\n",
    "#     else:\n",
    "#         chosen_models = [chosen_model.upper()]  # Capitalize input for case insensitivity\n",
    "\n",
    "#     eval_metrics = {}\n",
    "\n",
    "#     for model_name in chosen_models:\n",
    "#         if model_name not in models:\n",
    "#             print(f\"Model '{model_name}' not found. Skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         model = models[model_name]\n",
    "\n",
    "#         if model_name == 'Gradient Boosting':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'min_samples_leaf': [1, 2, 4],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'SVR':\n",
    "#             params = {\n",
    "#                 'C': [0.1, 1, 10],\n",
    "#                 'kernel': ['linear', 'rbf', 'poly'],\n",
    "#                 'gamma': ['scale', 'auto']\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'XGBoost':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         # For LSTM model\n",
    "#         elif model_name == 'LSTM':\n",
    "#             model.add(Dense(units=1))  # Add output layer\n",
    "#             model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#             X_train_array = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#             X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#             model.fit(X_train_array, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "#             # Save the trained LSTM model\n",
    "#             model_filename = f\"Model_ATOM/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             model.save(model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#             predictions = model.predict(X_test_array).flatten()\n",
    "\n",
    "#             # Calculate evaluation metrics\n",
    "#             mae = mean_absolute_error(y_test, predictions)\n",
    "#             mse = mean_squared_error(y_test, predictions)\n",
    "#             rmse = np.sqrt(mse)\n",
    "#             mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#             r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#             # Store evaluation metrics\n",
    "#             eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "#             continue  # Skip the rest of the loop for LSTM\n",
    "\n",
    "\n",
    "#         # For other models\n",
    "#         model.fit(X_train, y_train)  # Fit the model\n",
    "#         predictions = model.predict(X_test)\n",
    "#         # Calculate evaluation metrics\n",
    "#         mae = mean_absolute_error(y_test, predictions)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#         r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#         # Store evaluation metrics\n",
    "#         eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "        \n",
    "#         # Save the trained model\n",
    "#         if save_models:\n",
    "#             model_filename = f\"Model_ATOM/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             os.makedirs(os.path.dirname(model_filename), exist_ok=True)\n",
    "#             joblib.dump(model, model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#     # Display evaluation metrics\n",
    "#     for model_name, metrics in eval_metrics.items():\n",
    "#         print(f\"Evaluation metrics for {model_name}:\")\n",
    "#         for metric_name, value in metrics.items():\n",
    "#             print(f\"{metric_name}: {value}\")\n",
    "#         print()\n",
    "\n",
    "#     # Plot evaluation metrics\n",
    "#     if eval_metrics:\n",
    "#         # Plot evaluation metrics\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "#         metrics = list(eval_metrics.keys())\n",
    "#         mae_values = [eval_metrics[model]['MAE'] for model in metrics]  # Corrected access to values\n",
    "#         mse_values = [eval_metrics[model]['MSE'] for model in metrics]  # Corrected access to values\n",
    "#         rmse_values = [eval_metrics[model]['RMSE'] for model in metrics]  # Corrected access to values\n",
    "#         mape_values = [eval_metrics[model]['MAPE'] for model in metrics]  # Corrected access to values\n",
    "#         r2_values = [eval_metrics[model]['R2'] for model in metrics]  # Corrected access to values\n",
    "\n",
    "        \n",
    "#         bar_width = 0.15  # Increased bar width\n",
    "#         index = np.arange(len(metrics))\n",
    "\n",
    "#         bar1 = ax.bar(index - 2*bar_width, mae_values, bar_width, label='MAE')  # Adjusted positions for bars\n",
    "#         bar2 = ax.bar(index - bar_width, mse_values, bar_width, label='MSE')   # Adjusted positions for bars\n",
    "#         bar3 = ax.bar(index, rmse_values, bar_width, label='RMSE')              # Adjusted positions for bars\n",
    "#         # bar4 = ax.bar(index + bar_width, mape_values, bar_width, label='MAPE')  # Adjusted positions for bars\n",
    "\n",
    "#         ax.set_xlabel('Models')\n",
    "#         ax.set_ylabel('Metrics')\n",
    "#         ax.set_title(f'Evaluation Metrics for ATOM using {chosen_model.upper()} as the Models')\n",
    "#         ax.set_xticks(index)\n",
    "#         ax.set_xticklabels(metrics)\n",
    "#         ax.legend()\n",
    "\n",
    "#         # Annotate bars with values\n",
    "#         for bars in [bar1, bar2, bar3]:\n",
    "#             for bar in bars:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.annotate('{}'.format(round(height, 2)),\n",
    "#                             xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "#                             xytext=(0, 3),  # 3 points vertical offset\n",
    "#                             textcoords=\"offset points\",\n",
    "#                             ha='center', va='bottom')\n",
    "\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"No models were evaluated.\")\n",
    "\n",
    "\n",
    "# # Load the selected data from a CSV file\n",
    "# selected_data = pd.read_csv(\"Selected_coins.csv\", index_col='Date')\n",
    "# # Usage\n",
    "# print(\"Available models: Gradient Boosting, SVR, XGBoost, LSTM\")\n",
    "# chosen_model = input(\"Enter the model you want to evaluate (or type 'all' for all models): \").strip()\n",
    "# evaluate_models_ATOM(selected_data, chosen_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449dce0-54f6-40ba-9793-8d3acde442dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training the models with BTC-GBP  and saving\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from xgboost import XGBRegressor\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# def evaluate_models_BTC(selected_data, chosen_model='all', save_models=True):\n",
    "#     # Making a copy of the slice to ensure it's a separate object\n",
    "#     selected_data = selected_data.copy()\n",
    "\n",
    "#     for lag in range(1, 4):  # Adding lagged features for 1 to 3 days\n",
    "#         selected_data.loc[:, f'BTC-GBP_lag_{lag}'] = selected_data['BTC-GBP'].shift(lag)\n",
    "\n",
    "#     # Dropping rows with NaN values created due to shifting\n",
    "#     selected_data.dropna(inplace=True)\n",
    "\n",
    "#     # Features will be the lagged values, and the target will be the current BTC-GBP price\n",
    "#     features = [f'BTC-GBP_lag_{lag}' for lag in range(1, 4)]\n",
    "#     X = selected_data[features]\n",
    "#     y = selected_data['BTC-GBP']\n",
    "\n",
    "#     # Splitting the dataset into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize and train the models\n",
    "#     models = {\n",
    "#         'GRADIENT BOOSTING': GradientBoostingRegressor(),\n",
    "#         'SVR': SVR(),\n",
    "#         'XGBOOST': XGBRegressor(),\n",
    "#         'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "#     }\n",
    "\n",
    "#     if chosen_model.lower() == 'all':\n",
    "#         chosen_models = models.keys()\n",
    "#     else:\n",
    "#         chosen_models = [chosen_model.upper()]  # Capitalize input for case insensitivity\n",
    "\n",
    "#     eval_metrics = {}\n",
    "\n",
    "#     for model_name in chosen_models:\n",
    "#         if model_name not in models:\n",
    "#             print(f\"Model '{model_name}' not found. Skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         model = models[model_name]\n",
    "\n",
    "#         if model_name == 'Gradient Boosting':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'min_samples_leaf': [1, 2, 4],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'SVR':\n",
    "#             params = {\n",
    "#                 'C': [0.1, 1, 10],\n",
    "#                 'kernel': ['linear', 'rbf', 'poly'],\n",
    "#                 'gamma': ['scale', 'auto']\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'XGBoost':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "            \n",
    "#         # For LSTM model\n",
    "#         elif model_name == 'LSTM':\n",
    "#             model.add(Dense(units=1))  # Add output layer\n",
    "#             model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#             X_train_array = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#             X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#             model.fit(X_train_array, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "#             # Save the trained LSTM model\n",
    "#             model_filename = f\"Model_BTC/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             model.save(model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#             predictions = model.predict(X_test_array).flatten()\n",
    "\n",
    "#             # Calculate evaluation metrics\n",
    "#             mae = mean_absolute_error(y_test, predictions)\n",
    "#             mse = mean_squared_error(y_test, predictions)\n",
    "#             rmse = np.sqrt(mse)\n",
    "#             mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#             r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#             # Store evaluation metrics\n",
    "#             eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "#             continue  # Skip the rest of the loop for LSTM\n",
    "\n",
    "\n",
    "#         # For other models\n",
    "#         model.fit(X_train, y_train)  # Fit the model\n",
    "#         predictions = model.predict(X_test)\n",
    "#         # Calculate evaluation metrics\n",
    "#         mae = mean_absolute_error(y_test, predictions)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#         r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#         # Store evaluation metrics\n",
    "#         eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "        \n",
    "#         # Save the trained model\n",
    "#         if save_models:\n",
    "#             model_filename = f\"Model_BTC/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             os.makedirs(os.path.dirname(model_filename), exist_ok=True)\n",
    "#             joblib.dump(model, model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#     # Display evaluation metrics\n",
    "#     for model_name, metrics in eval_metrics.items():\n",
    "#         print(f\"Evaluation metrics for {model_name}:\")\n",
    "#         for metric_name, value in metrics.items():\n",
    "#             print(f\"{metric_name}: {value}\")\n",
    "#         print()\n",
    "\n",
    "#     # Plot evaluation metrics\n",
    "#     if eval_metrics:\n",
    "#         # Plot evaluation metrics\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "#         metrics = list(eval_metrics.keys())\n",
    "#         mae_values = [eval_metrics[model]['MAE'] for model in metrics]  # Corrected access to values\n",
    "#         mse_values = [eval_metrics[model]['MSE'] for model in metrics]  # Corrected access to values\n",
    "#         rmse_values = [eval_metrics[model]['RMSE'] for model in metrics]  # Corrected access to values\n",
    "#         mape_values = [eval_metrics[model]['MAPE'] for model in metrics]  # Corrected access to values\n",
    "#         r2_values = [eval_metrics[model]['R2'] for model in metrics]  # Corrected access to values\n",
    "\n",
    "        \n",
    "#         bar_width = 0.15  # Increased bar width\n",
    "#         index = np.arange(len(metrics))\n",
    "\n",
    "#         bar1 = ax.bar(index - 2*bar_width, mae_values, bar_width, label='MAE')  # Adjusted positions for bars\n",
    "#         bar2 = ax.bar(index - bar_width, mse_values, bar_width, label='MSE')   # Adjusted positions for bars\n",
    "#         bar3 = ax.bar(index, rmse_values, bar_width, label='RMSE')              # Adjusted positions for bars\n",
    "#         # bar4 = ax.bar(index + bar_width, mape_values, bar_width, label='MAPE')  # Adjusted positions for bars\n",
    "\n",
    "#         ax.set_xlabel('Models')\n",
    "#         ax.set_ylabel('Metrics')\n",
    "#         ax.set_title(f'Evaluation Metrics for BTC using {chosen_model.upper()} as the Models')\n",
    "#         ax.set_xticks(index)\n",
    "#         ax.set_xticklabels(metrics)\n",
    "#         ax.legend()\n",
    "\n",
    "#         # Annotate bars with values\n",
    "#         for bars in [bar1, bar2, bar3]:\n",
    "#             for bar in bars:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.annotate('{}'.format(round(height, 2)),\n",
    "#                             xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "#                             xytext=(0, 3),  # 3 points vertical offset\n",
    "#                             textcoords=\"offset points\",\n",
    "#                             ha='center', va='bottom')\n",
    "\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"No models were evaluated.\")\n",
    "\n",
    "# # Usage\n",
    "# print(\"Available models: Gradient Boosting, SVR, XGBoost, LSTM\")\n",
    "# chosen_model = input(\"Enter the model you want to evaluate (or type 'all' for all models): \").strip()\n",
    "# evaluate_models_BTC(selected_data, chosen_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fc3d3-a6cf-4ad6-84b7-8156de1d05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training the models with AXS and saving\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from xgboost import XGBRegressor\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# def evaluate_models_AXS(selected_data, chosen_model='all', save_models=True):\n",
    "#     # Making a copy of the slice to ensure it's a separate object\n",
    "#     selected_data = selected_data.copy()\n",
    "\n",
    "#     for lag in range(1, 4):  # Adding lagged features for 1 to 3 days\n",
    "#         selected_data.loc[:, f'AXS-GBP_lag_{lag}'] = selected_data['AXS-GBP'].shift(lag)\n",
    "\n",
    "#     # Dropping rows with NaN values created due to shifting\n",
    "#     selected_data.dropna(inplace=True)\n",
    "\n",
    "#     # Features will be the lagged values, and the target will be the current BTC-GBP price\n",
    "#     features = [f'AXS-GBP_lag_{lag}' for lag in range(1, 4)]\n",
    "#     X = selected_data[features]\n",
    "#     y = selected_data['AXS-GBP']\n",
    "\n",
    "#     # Splitting the dataset into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize and train the models\n",
    "#     models = {\n",
    "#         'GRADIENT BOOSTING': GradientBoostingRegressor(),\n",
    "#         'SVR': SVR(),\n",
    "#         'XGBOOST': XGBRegressor(),\n",
    "#         'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "#     }\n",
    "\n",
    "#     if chosen_model.lower() == 'all':\n",
    "#         chosen_models = models.keys()\n",
    "#     else:\n",
    "#         chosen_models = [chosen_model.upper()]  # Capitalize input for case insensitivity\n",
    "\n",
    "#     eval_metrics = {}\n",
    "\n",
    "#     for model_name in chosen_models:\n",
    "#         if model_name not in models:\n",
    "#             print(f\"Model '{model_name}' not found. Skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         model = models[model_name]\n",
    "\n",
    "#         if model_name == 'Gradient Boosting':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'min_samples_leaf': [1, 2, 4],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'SVR':\n",
    "#             params = {\n",
    "#                 'C': [0.1, 1, 10],\n",
    "#                 'kernel': ['linear', 'rbf', 'poly'],\n",
    "#                 'gamma': ['scale', 'auto']\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'XGBoost':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         # For LSTM model\n",
    "#         elif model_name == 'LSTM':\n",
    "#             model.add(Dense(units=1))  # Add output layer\n",
    "#             model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#             X_train_array = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#             X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#             model.fit(X_train_array, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "#             # Save the trained LSTM model\n",
    "#             model_filename = f\"Model_AXS/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             model.save(model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#             predictions = model.predict(X_test_array).flatten()\n",
    "\n",
    "#             # Calculate evaluation metrics\n",
    "#             mae = mean_absolute_error(y_test, predictions)\n",
    "#             mse = mean_squared_error(y_test, predictions)\n",
    "#             rmse = np.sqrt(mse)\n",
    "#             mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#             r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#             # Store evaluation metrics\n",
    "#             eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "#             continue  # Skip the rest of the loop for LSTM\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "#         # For other models\n",
    "#         model.fit(X_train, y_train)  # Fit the model\n",
    "#         predictions = model.predict(X_test)\n",
    "#         # Calculate evaluation metrics\n",
    "#         mae = mean_absolute_error(y_test, predictions)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#         r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#         # Store evaluation metrics\n",
    "#         eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "        \n",
    "#          # Save the trained model\n",
    "#         if save_models:\n",
    "#             model_filename = f\"Model_AXS/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             os.makedirs(os.path.dirname(model_filename), exist_ok=True)\n",
    "#             joblib.dump(model, model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#     # Display evaluation metrics\n",
    "#     for model_name, metrics in eval_metrics.items():\n",
    "#         print(f\"Evaluation metrics for {model_name}:\")\n",
    "#         for metric_name, value in metrics.items():\n",
    "#             print(f\"{metric_name}: {value}\")\n",
    "#         print()\n",
    "\n",
    "#     # Plot evaluation metrics\n",
    "#     if eval_metrics:\n",
    "#         # Plot evaluation metrics\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "#         metrics = list(eval_metrics.keys())\n",
    "#         mae_values = [eval_metrics[model]['MAE'] for model in metrics]  # Corrected access to values\n",
    "#         mse_values = [eval_metrics[model]['MSE'] for model in metrics]  # Corrected access to values\n",
    "#         rmse_values = [eval_metrics[model]['RMSE'] for model in metrics]  # Corrected access to values\n",
    "#         mape_values = [eval_metrics[model]['MAPE'] for model in metrics]  # Corrected access to values\n",
    "#         r2_values = [eval_metrics[model]['R2'] for model in metrics]  # Corrected access to values\n",
    "\n",
    "        \n",
    "#         bar_width = 0.15  # Increased bar width\n",
    "#         index = np.arange(len(metrics))\n",
    "\n",
    "#         bar1 = ax.bar(index - 2*bar_width, mae_values, bar_width, label='MAE')  # Adjusted positions for bars\n",
    "#         bar2 = ax.bar(index - bar_width, mse_values, bar_width, label='MSE')   # Adjusted positions for bars\n",
    "#         bar3 = ax.bar(index, rmse_values, bar_width, label='RMSE')              # Adjusted positions for bars\n",
    "#         # bar4 = ax.bar(index + bar_width, mape_values, bar_width, label='MAPE')  # Adjusted positions for bars\n",
    "\n",
    "#         ax.set_xlabel('Models')\n",
    "#         ax.set_ylabel('Metrics')\n",
    "#         ax.set_title(f'Evaluation Metrics for AXS using {chosen_model.upper()} as the Models')\n",
    "#         ax.set_xticks(index)\n",
    "#         ax.set_xticklabels(metrics)\n",
    "#         ax.legend()\n",
    "\n",
    "#         # Annotate bars with values\n",
    "#         for bars in [bar1, bar2, bar3]:\n",
    "#             for bar in bars:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.annotate('{}'.format(round(height, 2)),\n",
    "#                             xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "#                             xytext=(0, 3),  # 3 points vertical offset\n",
    "#                             textcoords=\"offset points\",\n",
    "#                             ha='center', va='bottom')\n",
    "\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"No models were evaluated.\")\n",
    "\n",
    "# # Usage\n",
    "# print(\"Available models: Gradient Boosting, SVR, XGBoost, LSTM\")\n",
    "# chosen_model = input(\"Enter the model you want to evaluate (or type 'all' for all models): \").strip()\n",
    "# evaluate_models_AXS(selected_data, chosen_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37591ef9-f3bb-4aa6-b1f1-9c2b8d5e0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training the models with BCH and saving\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from xgboost import XGBRegressor\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# def evaluate_models_BCH(selected_data, chosen_model='all', save_models=True):\n",
    "#     # Making a copy of the slice to ensure it's a separate object\n",
    "#     selected_data = selected_data.copy()\n",
    "\n",
    "#     for lag in range(1, 4):  # Adding lagged features for 1 to 3 days\n",
    "#         selected_data.loc[:, f'BCH-GBP_lag_{lag}'] = selected_data['BCH-GBP'].shift(lag)\n",
    "\n",
    "#     # Dropping rows with NaN values created due to shifting\n",
    "#     selected_data.dropna(inplace=True)\n",
    "\n",
    "#     # Features will be the lagged values, and the target will be the current BTC-GBP price\n",
    "#     features = [f'BCH-GBP_lag_{lag}' for lag in range(1, 4)]\n",
    "#     X = selected_data[features]\n",
    "#     y = selected_data['BCH-GBP']\n",
    "\n",
    "#     # Splitting the dataset into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize and train the models\n",
    "#     models = {\n",
    "#         'GRADIENT BOOSTING': GradientBoostingRegressor(),\n",
    "#         'SVR': SVR(),\n",
    "#         'XGBOOST': XGBRegressor(),\n",
    "#         'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "#     }\n",
    "\n",
    "#     if chosen_model.lower() == 'all':\n",
    "#         chosen_models = models.keys()\n",
    "#     else:\n",
    "#         chosen_models = [chosen_model.upper()]  # Capitalize input for case insensitivity\n",
    "\n",
    "#     eval_metrics = {}\n",
    "\n",
    "#     for model_name in chosen_models:\n",
    "#         if model_name not in models:\n",
    "#             print(f\"Model '{model_name}' not found. Skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         model = models[model_name]\n",
    "\n",
    "#         if model_name == 'Gradient Boosting':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'min_samples_leaf': [1, 2, 4],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'SVR':\n",
    "#             params = {\n",
    "#                 'C': [0.1, 1, 10],\n",
    "#                 'kernel': ['linear', 'rbf', 'poly'],\n",
    "#                 'gamma': ['scale', 'auto']\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'XGBoost':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#             # For LSTM model\n",
    "#             # For LSTM model\n",
    "#         elif model_name == 'LSTM':\n",
    "#             model.add(Dense(units=1))  # Add output layer\n",
    "#             model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#             X_train_array = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#             X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#             model.fit(X_train_array, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "#             # Save the trained LSTM model\n",
    "#             model_filename = f\"Model_BCH/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             model.save(model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#             predictions = model.predict(X_test_array).flatten()\n",
    "\n",
    "#             # Calculate evaluation metrics\n",
    "#             mae = mean_absolute_error(y_test, predictions)\n",
    "#             mse = mean_squared_error(y_test, predictions)\n",
    "#             rmse = np.sqrt(mse)\n",
    "#             mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#             r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#             # Store evaluation metrics\n",
    "#             eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "            \n",
    "#             continue  # Skip the rest of the loop for LSTM\n",
    "\n",
    "\n",
    "#         # For other models\n",
    "#         model.fit(X_train, y_train)  # Fit the model\n",
    "#         predictions = model.predict(X_test)\n",
    "#         # Calculate evaluation metrics\n",
    "#         mae = mean_absolute_error(y_test, predictions)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#         r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#         # Store evaluation metrics\n",
    "#         eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "        \n",
    "#          # Save the trained model\n",
    "#         if save_models:\n",
    "#             model_filename = f\"Model_BCH/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             os.makedirs(os.path.dirname(model_filename), exist_ok=True)\n",
    "#             joblib.dump(model, model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#     # Display evaluation metrics\n",
    "#     for model_name, metrics in eval_metrics.items():\n",
    "#         print(f\"Evaluation metrics for {model_name}:\")\n",
    "#         for metric_name, value in metrics.items():\n",
    "#             print(f\"{metric_name}: {value}\")\n",
    "#         print()\n",
    "\n",
    "#     # Plot evaluation metrics\n",
    "#     if eval_metrics:\n",
    "#         # Plot evaluation metrics\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "#         metrics = list(eval_metrics.keys())\n",
    "#         mae_values = [eval_metrics[model]['MAE'] for model in metrics]  # Corrected access to values\n",
    "#         mse_values = [eval_metrics[model]['MSE'] for model in metrics]  # Corrected access to values\n",
    "#         rmse_values = [eval_metrics[model]['RMSE'] for model in metrics]  # Corrected access to values\n",
    "#         mape_values = [eval_metrics[model]['MAPE'] for model in metrics]  # Corrected access to values\n",
    "#         r2_values = [eval_metrics[model]['R2'] for model in metrics]  # Corrected access to values\n",
    "\n",
    "        \n",
    "#         bar_width = 0.15  # Increased bar width\n",
    "#         index = np.arange(len(metrics))\n",
    "\n",
    "#         bar1 = ax.bar(index - 2*bar_width, mae_values, bar_width, label='MAE')  # Adjusted positions for bars\n",
    "#         bar2 = ax.bar(index - bar_width, mse_values, bar_width, label='MSE')   # Adjusted positions for bars\n",
    "#         bar3 = ax.bar(index, rmse_values, bar_width, label='RMSE')              # Adjusted positions for bars\n",
    "#         # bar4 = ax.bar(index + bar_width, mape_values, bar_width, label='MAPE')  # Adjusted positions for bars\n",
    "\n",
    "#         ax.set_xlabel('Models')\n",
    "#         ax.set_ylabel('Metrics')\n",
    "#         ax.set_title(f'Evaluation Metrics for BCH using {chosen_model.upper()} as the Models')\n",
    "#         ax.set_xticks(index)\n",
    "#         ax.set_xticklabels(metrics)\n",
    "#         ax.legend()\n",
    "\n",
    "#         # Annotate bars with values\n",
    "#         for bars in [bar1, bar2, bar3]:\n",
    "#             for bar in bars:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.annotate('{}'.format(round(height, 2)),\n",
    "#                             xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "#                             xytext=(0, 3),  # 3 points vertical offset\n",
    "#                             textcoords=\"offset points\",\n",
    "#                             ha='center', va='bottom')\n",
    "\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"No models were evaluated.\")\n",
    "        \n",
    "    \n",
    "\n",
    "# # Usage\n",
    "# print(\"Available models: Gradient Boosting, SVR, XGBoost, LSTM\")\n",
    "# chosen_model = input(\"Enter the model you want to evaluate (or type 'all' for all models): \").strip()\n",
    "# evaluate_models_BCH(selected_data, chosen_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efba88-a682-42cd-8505-7311c96f6e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
