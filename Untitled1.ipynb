{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156da91b-1f9d-4fec-9f4a-fa4bbaeedc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def plot_average_prices(predictions, periods, frequency, mse):\n",
    "    \"\"\"\n",
    "    Plot average prices with confidence intervals.\n",
    "    \"\"\"\n",
    "    upper_bound = predictions + 1.96 * np.sqrt(mse)\n",
    "    lower_bound = predictions - 1.96 * np.sqrt(mse)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(periods, predictions, label='Predicted Price')\n",
    "    plt.fill_between(periods, lower_bound, upper_bound, color='b', alpha=0.2, label='95% Confidence Interval')\n",
    "    plt.title(f\"Average Prices and Confidence Intervals for by {frequency}\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    st.pyplot(plt)\n",
    "\n",
    "def plot_actual_forecast_with_confidence(actual, predictions, periods, upper_bound, lower_bound):\n",
    "    \"\"\"\n",
    "    Plot actual prices and forecasted prices with confidence intervals.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(periods, actual, label='Actual Price', color='g')\n",
    "    plt.plot(periods, predictions, label='Forecasted Price', color='r')\n",
    "    plt.fill_between(periods, lower_bound, upper_bound, color='b', alpha=0.2, label='95% Confidence Interval')\n",
    "    plt.title(\"Actual and Forecasted Prices with Confidence Intervals\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    st.pyplot(plt)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    return pd.read_csv(\"Selected_coins.csv\", index_col='Date')\n",
    "\n",
    "def evaluate_models_coin(selected_data, coin_name, coin_index):\n",
    "    \"\"\"\n",
    "    Evaluate different models for cryptocurrency price prediction.\n",
    "    \"\"\"\n",
    "    # Create lagged features for 1 to 3 days\n",
    "    for lag in range(1, 4):\n",
    "        selected_data[f'{coin_name}_lag_{lag}'] = selected_data[coin_name].shift(lag)\n",
    "\n",
    "    # Remove rows with missing values due to lag creation\n",
    "    selected_data.dropna(inplace=True)\n",
    "\n",
    "    features = [f'{coin_name}_lag_{lag}' for lag in range(1, 4)]\n",
    "    X = selected_data[features]\n",
    "    y = selected_data[coin_name]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Prepare dictionary of models\n",
    "    models = {\n",
    "        'Gradient Boosting': GradientBoostingRegressor(),\n",
    "        'Support Vector Regression': SVR(),\n",
    "        'XGBoost': XGBRegressor(),\n",
    "        'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "    }\n",
    "\n",
    "    # Attempt to load pre-trained models, except LSTM\n",
    "    model_choices = st.selectbox('Choose a model:', list(models.keys()))\n",
    "    \n",
    "    model = models[model_choices]\n",
    "    if model_choices != 'LSTM':\n",
    "        model.fit(X_train, y_train)\n",
    "    elif model_choices == 'LSTM':\n",
    "        model_filename = f\"Model_SELECTED_COIN_{coin_index+1}/lstm_model.pkl\"\n",
    "        if os.path.exists(model_filename):\n",
    "            model = tf.keras.models.load_model(model_filename)\n",
    "            X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "            predictions = model.predict(X_test_array).flatten()\n",
    "        else:\n",
    "            st.error(\"No pre-trained LSTM model found.\")\n",
    "            return None, None, None, None\n",
    "\n",
    "    return model, X_test, y_test, coin_index\n",
    "\n",
    "def plot_predictions(model, selected_data, X_test, y_test, coin_index):\n",
    "    if model:\n",
    "        coin_name = selected_data.columns[coin_index]\n",
    "        \n",
    "        frequency = input(f\"Enter the frequency for {coin_name} (daily, weekly, monthly, quarterly): \").lower()\n",
    "        num_periods = int(input(f\"Enter the number of periods for {coin_name}: \"))\n",
    "\n",
    "        features = [f'{coin_name}_lag_{lag}' for lag in range(1, 4)]\n",
    "        X_array = selected_data[features].to_numpy()\n",
    "        predictions = model.predict(X_array[-num_periods:])\n",
    "        \n",
    "        last_date = selected_data.index[-1]\n",
    "        period_map = {'daily': 'D', 'weekly': 'W', 'monthly': 'M', 'quarterly': 'Q'}\n",
    "        \n",
    "        if frequency in period_map:\n",
    "            periods = pd.date_range(start=last_date, periods=num_periods, freq=period_map[frequency])\n",
    "        else:\n",
    "            print(\"Invalid frequency. Please choose a valid option.\")\n",
    "            return\n",
    "        \n",
    "        mse = mean_squared_error(y_test[-num_periods:], predictions)\n",
    "        \n",
    "        # Plotting all required charts\n",
    "        plot_average_prices(predictions, periods, frequency, mse)\n",
    "        upper_bound = predictions + 1.96 * np.sqrt(mse)\n",
    "        lower_bound = predictions - 1.96 * np.sqrt(mse)\n",
    "        plot_actual_forecast_with_confidence(y_test[-num_periods:], predictions, periods, upper_bound, lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4627416-ff4d-4652-86f6-53ed0ddeb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from xgboost import XGBRegressor\n",
    "# from tensorflow.keras.models import Sequential, load_model\n",
    "# from tensorflow.keras.layers import LSTM, Dense\n",
    "# import os\n",
    "\n",
    "# # Function to evaluate models for selected coins\n",
    "# def evaluate_models_selected_coin(selected_data, column_index, chosen_model='all'):\n",
    "#     coin_name = selected_data.columns[column_index] \n",
    "\n",
    "#     # Add lagged features for 1 to 3 days\n",
    "#     for lag in range(1, 4):\n",
    "#         selected_data.loc[:, f'{coin_name}_lag_{lag}'] = selected_data[coin_name].shift(lag)\n",
    "\n",
    "#     # Drop rows with NaN values created due to shifting\n",
    "#     selected_data.dropna(inplace=True)\n",
    "\n",
    "#     # Features will be the lagged values, and the target will be the current price of the coin\n",
    "#     features = [f'{coin_name}_lag_{lag}' for lag in range(1, 4)]\n",
    "#     X = selected_data[features]\n",
    "#     y = selected_data[coin_name]\n",
    "\n",
    "#     # Split the dataset into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize dictionary to hold models\n",
    "#     models = {\n",
    "#         'GRADIENT BOOSTING': GradientBoostingRegressor(),\n",
    "#         'SVR': SVR(),\n",
    "#         'XGBOOST': XGBRegressor(),\n",
    "#         'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "#     }\n",
    "\n",
    "#     eval_metrics = {}\n",
    "\n",
    "#     if chosen_model.lower() == 'all':\n",
    "#         chosen_models = models.keys()\n",
    "#     else:\n",
    "#         chosen_models = [chosen_model.upper()]  # Capitalize input for case insensitivity\n",
    "\n",
    "#     for model_name in chosen_models:\n",
    "#         if model_name not in models:\n",
    "#             st.warning(f\"Model '{model_name}' not found. Skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         model = models[model_name]\n",
    "\n",
    "#         if model_name == 'LSTM':\n",
    "#             model_filename = f\"Model_SELECTED_COIN_{column_index+1}/lstm_model.pkl\"\n",
    "#             if os.path.exists(model_filename):\n",
    "#                 model = load_model(model_filename)\n",
    "#                 # Reshape the input data for LSTM model\n",
    "#                 X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#                 predictions = model.predict(X_test_array).flatten()\n",
    "#             else:\n",
    "#                 st.error(\"No pre-trained LSTM model found.\")\n",
    "#                 return  # Skip the rest of the loop if LSTM model not found\n",
    "#         else:\n",
    "#             model.fit(X_train, y_train)  # Fit the model\n",
    "#             predictions = model.predict(X_test)\n",
    "\n",
    "#         # Calculate evaluation metrics\n",
    "#         mae = mean_absolute_error(y_test, predictions)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#         r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#         # Store evaluation metrics\n",
    "#         eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "\n",
    "#     # Display evaluation metrics\n",
    "#     st.subheader(f\"Evaluation Metrics for {coin_name}:\")\n",
    "#     for model_name, metrics in eval_metrics.items():\n",
    "#         st.write(f\"Evaluation metrics for {model_name}:\")\n",
    "#         for metric_name, value in metrics.items():\n",
    "#             st.write(f\"{metric_name}: {value}\")\n",
    "#         st.write('---')\n",
    "\n",
    "#     # Plot evaluation metrics\n",
    "#     if eval_metrics:\n",
    "#         st.subheader(\"Evaluation Metric Visualization\")\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "#         metrics = list(eval_metrics.keys())\n",
    "#         mae_values = [eval_metrics[model]['MAE'] for model in metrics]\n",
    "#         mse_values = [eval_metrics[model]['MSE'] for model in metrics]\n",
    "#         rmse_values = [eval_metrics[model]['RMSE'] for model in metrics]\n",
    "\n",
    "#         bar_width = 0.15\n",
    "#         index = np.arange(len(metrics))\n",
    "\n",
    "#         bar1 = ax.bar(index - 2*bar_width, mae_values, bar_width, label='MAE')\n",
    "#         bar2 = ax.bar(index - bar_width, mse_values, bar_width, label='MSE')\n",
    "#         bar3 = ax.bar(index, rmse_values, bar_width, label='RMSE')\n",
    "\n",
    "#         ax.set_xlabel('Models')\n",
    "#         ax.set_ylabel('Metrics')\n",
    "#         ax.set_title(f'Evaluation Metrics for {coin_name} using {chosen_model.upper()} as the Models')\n",
    "#         ax.set_xticks(index)\n",
    "#         ax.set_xticklabels(metrics)\n",
    "#         ax.legend()\n",
    "\n",
    "#         # Annotate bars with values\n",
    "#         for bars in [bar1, bar2, bar3]:\n",
    "#             for bar in bars:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.annotate('{}'.format(round(height, 2)),\n",
    "#                             xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "#                             xytext=(0, 3),  # 3 points vertical offset\n",
    "#                             textcoords=\"offset points\",\n",
    "#                             ha='center', va='bottom')\n",
    "\n",
    "#         st.pyplot(fig)\n",
    "#     else:\n",
    "#         st.error(\"No models were evaluated.\")\n",
    "\n",
    "# def plot_predictions(model, selected_data, X_test, y_test, coin_index):\n",
    "#     if model is not None:\n",
    "#         coin_name = selected_data.columns[coin_index]  # Get the name of the coin based on index\n",
    "        \n",
    "#         # User input for frequency and number of periods (weeks, months, or quarters)\n",
    "#         frequency = st.selectbox(f\"Select frequency for {coin_name}\", ['Daily', 'Weekly', 'Monthly', 'Quarterly']).lower()\n",
    "#         num_periods = st.number_input(f\"Enter the number of periods for {coin_name}\", min_value=1, step=1)\n",
    "\n",
    "#         # Make predictions for the specified number of periods\n",
    "#         features = [f'{coin_name}_lag_{lag}' for lag in range(1, 4)]\n",
    "#         X_array = selected_data[features].to_numpy()\n",
    "#         predictions = model.predict(X_array[-num_periods:])  # Predictions for the last 'num_periods' rows\n",
    "\n",
    "#         # Get the last date in the dataset\n",
    "#         last_date = selected_data.index[-1]\n",
    "\n",
    "#         # Generate periods for future predictions\n",
    "#         if frequency == 'daily':\n",
    "#             periods = pd.date_range(start=last_date, periods=num_periods, freq='D')\n",
    "#         elif frequency == 'weekly':\n",
    "#             periods = pd.date_range(start=last_date, periods=num_periods, freq='W')\n",
    "#         elif frequency == 'monthly':\n",
    "#             periods = pd.date_range(start=last_date, periods=num_periods, freq='M')\n",
    "#         elif frequency == 'quarterly':\n",
    "#             periods = pd.date_range(start=last_date, periods=num_periods, freq='Q')\n",
    "#         else:\n",
    "#             st.error(\"Invalid frequency. Please choose from 'daily', 'weekly', 'monthly', or 'quarterly'.\")\n",
    "\n",
    "#         # Calculate prediction intervals\n",
    "#         predictions_series = pd.Series(predictions, index=periods)\n",
    "#         pred_int = sm.tools.eval_measures.prediction_interval(predictions_series)\n",
    "\n",
    "#         # Plot average prices with confidence intervals\n",
    "#         mse = mean_squared_error(y_test[-num_periods:], predictions)\n",
    "#         st.write(f\"Mean Squared Error for {coin_name}: {mse}\")\n",
    "\n",
    "#         # Creating a time series plot with predicted prices and confidence intervals\n",
    "#         st.subheader(f\"Predicted Prices and Confidence Intervals for {coin_name} by {frequency}\")\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(periods, predictions, label='Predicted Price')\n",
    "#         plt.fill_between(pred_int.index, pred_int.iloc[:, 0], pred_int.iloc[:, 1], color='blue', alpha=0.2, label='95% Prediction Interval')\n",
    "#         plt.title(f\"Predicted Prices for {coin_name} by {frequency}\")\n",
    "#         plt.xlabel('Date')\n",
    "#         plt.ylabel('Price')\n",
    "#         plt.legend()\n",
    "#         plt.grid(True)\n",
    "#         st.pyplot()\n",
    "\n",
    "# Sidebar navigation\n",
    "# page = st.sidebar.radio(\"Navigation\", [\"Evaluate Models\", \"Predictions\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# # prediction graphs\n",
    "\n",
    "# # Function to evaluate different models for the coin price prediction\n",
    "# def evaluate_models_coin(selected_data, coin_index):\n",
    "#     coin_name = selected_data.columns[coin_index]  # Get the name of the coin based on index\n",
    "#     # Add lagged features for 1 to 3 days\n",
    "#     for lag in range(1, 4):\n",
    "#         selected_data.loc[:, f'{coin_name}_lag_{lag}'] = selected_data[coin_name].shift(lag)\n",
    "\n",
    "#     # Drop rows with NaN values created due to shifting\n",
    "#     selected_data.dropna(inplace=True)\n",
    "\n",
    "#     # Features will be the lagged values, and the target will be the current price of the coin\n",
    "#     features = [f'{coin_name}_lag_{lag}' for lag in range(1, 4)]\n",
    "#     X = selected_data[features]\n",
    "#     y = selected_data[coin_name]\n",
    "\n",
    "#     # Split the dataset into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize dictionary to hold models\n",
    "#     models = {\n",
    "#         'GBR': GradientBoostingRegressor(),\n",
    "#         'SVR': SVR(),\n",
    "#         'XGB': XGBRegressor(),  # Alias for XGBoost\n",
    "#         'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "#     }\n",
    "#     # Load pre-trained models for SVR, XGBoost, and Gradient Boosting\n",
    "#     for model_name in ['SVR', 'XGBoost', 'Gradient Boosting']:\n",
    "#         model_filename = f\"Model_SELECTED_COIN_{coin_index+1}/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#         if os.path.exists(model_filename):\n",
    "#             models[model_name] = joblib.load(model_filename)\n",
    "#         else:\n",
    "#             st.warning(f\"No pre-trained model found for {model_name}. Skipping...\")\n",
    "\n",
    "#     # User input for selecting the model\n",
    "#     model_choice = st.selectbox(f\"Select model for {coin_name}\", ['SVR', 'XGB', 'GBR', 'LSTM'])\n",
    "\n",
    "#     # Initialize and train the selected model\n",
    "#     if model_choice in models:\n",
    "#         model = models[model_choice]\n",
    "#         if model_choice != 'LSTM':\n",
    "#             model.fit(X_train, y_train)\n",
    "#     elif model_choice == 'LSTM':\n",
    "#         model_filename = f\"Model_SELECTED_COIN_{coin_index+1}/lstm_model.pkl\"\n",
    "#         if os.path.exists(model_filename):\n",
    "#             model = tf.keras.models.load_model(model_filename)\n",
    "#             # Reshape the input data for LSTM model\n",
    "#             X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#             predictions = model.predict(X_test_array).flatten()\n",
    "#         else:\n",
    "#             st.error(f\"No pre-trained LSTM model found for {coin_name}.\")\n",
    "#             return None, None, None, None\n",
    "#     else:\n",
    "#         st.error(\"Invalid model choice. Please choose from SVR, XGB, GBR, or LSTM.\")\n",
    "#         return None, None, None, None\n",
    "\n",
    "#     return model, selected_data, X_test, y_test\n",
    "\n",
    "# # Function to plot predictions and confidence intervals\n",
    "def plot_predictions(model, selected_data, X_test, y_test, coin_index):\n",
    "    if model is not None:\n",
    "        coin_list = selected_data.columns.tolist()\n",
    "        coin_index = st.selectbox('Select a coin for prediction:', coin_list)\n",
    "        coin_name = selected_data.columns[coin_index]  # Get the name of the coin based on index\n",
    "        \n",
    "        # User input for frequency and number of periods (weeks, months, or quarters)\n",
    "        frequency = st.selectbox(f\"Select frequency for {coin_name}\", ['Daily', 'Weekly', 'Monthly', 'Quarterly']).lower()\n",
    "        num_periods = st.number_input(f\"Enter the number of periods for {coin_name}\", min_value=1, step=1)\n",
    "\n",
    "        # Make predictions for the specified number of periods\n",
    "        features = [f'{coin_name}_lag_{lag}' for lag in range(1, 4)]\n",
    "        X_array = selected_data[features].to_numpy()\n",
    "        predictions = model.predict(X_array[-num_periods:])  # Predictions for the last 'num_periods' rows\n",
    "\n",
    "        # Get the last date in the dataset\n",
    "        last_date = selected_data.index[-1]\n",
    "\n",
    "        # Generate periods for future predictions\n",
    "        if frequency == 'daily':\n",
    "            periods = pd.date_range(start=last_date, periods=num_periods, freq='D')\n",
    "        elif frequency == 'weekly':\n",
    "            periods = pd.date_range(start=last_date, periods=num_periods, freq='W')\n",
    "        elif frequency == 'monthly':\n",
    "            periods = pd.date_range(start=last_date, periods=num_periods, freq='M')\n",
    "        elif frequency == 'quarterly':\n",
    "            periods = pd.date_range(start=last_date, periods=num_periods, freq='Q')\n",
    "        else:\n",
    "            st.error(\"Invalid frequency. Please choose from 'daily', 'weekly', 'monthly', or 'quarterly'.\")\n",
    "\n",
    "        # Plot average prices with confidence intervals\n",
    "        mse = mean_squared_error(y_test[-num_periods:], predictions)\n",
    "        st.write(f\"Mean Squared Error for {coin_name}: {mse}\")\n",
    "\n",
    "        # Creating a time series plot with predicted prices\n",
    "        st.subheader(f\"Predicted Prices and Confidence Intervals for {coin_name} by {frequency}\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(periods, predictions, label='Predicted Price')\n",
    "        plt.title(f\"Predicted Prices for {coin_name} by {frequency}\")\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        st.pyplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7592a3-56b3-477d-9f47-0e20062bbba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0599ca8-7be5-440a-9ec1-cdc9a25ea68f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Service\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def scrape_dynamic_content(url):\n",
    "    # Set up Selenium\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    service = Service('path/to/chromedriver')  # Replace 'path/to/chromedriver' with the path to your chromedriver\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for dynamic content to load (you may need to adjust the wait time)\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    # Extract elements with dynamic content\n",
    "    headlines = driver.find_elements(By.XPATH, '//div[@class=\"dynamic-content\"]/h2')\n",
    "    contents = driver.find_elements(By.XPATH, '//div[@class=\"dynamic-content\"]/p')\n",
    "\n",
    "    # Extract text from elements\n",
    "    scraped_data = []\n",
    "    for headline, content in zip(headlines, contents):\n",
    "        scraped_data.append({\n",
    "            'headline': headline.text.strip(),\n",
    "            'content': content.text.strip()\n",
    "        })\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    return scraped_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://example.com'  # Replace with the URL of the website you want to scrape\n",
    "    scraped_data = scrape_dynamic_content(url)\n",
    "    for idx, data in enumerate(scraped_data, start=1):\n",
    "        print(f\"Article {idx}:\")\n",
    "        print(f\"Headline: {data['headline']}\")\n",
    "        print(f\"Content: {data['content']}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a74259-56b5-49e6-b811-cfcd7c79cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training the models with ATOM-GBP and saving\n",
    "\n",
    "# import joblib\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from xgboost import XGBRegressor\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# def evaluate_models_ATOM(selected_data, chosen_model='all', save_models=True):\n",
    "#     # Making a copy of the slice to ensure it's a separate object\n",
    "#     selected_data = selected_data.copy()\n",
    "\n",
    "#     for lag in range(1, 4):  # Adding lagged features for 1 to 3 days\n",
    "#         selected_data.loc[:, f'ATOM-GBP_lag_{lag}'] = selected_data['ATOM-GBP'].shift(lag)\n",
    "\n",
    "#     # Dropping rows with NaN values created due to shifting\n",
    "#     selected_data.dropna(inplace=True)\n",
    "\n",
    "#     # Features will be the lagged values, and the target will be the current BTC-GBP price\n",
    "#     features = [f'ATOM-GBP_lag_{lag}' for lag in range(1, 4)]\n",
    "#     X = selected_data[features]\n",
    "#     y = selected_data['ATOM-GBP']\n",
    "\n",
    "#     # Splitting the dataset into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize and train the models\n",
    "#     models = {\n",
    "#         'GRADIENT BOOSTING': GradientBoostingRegressor(),\n",
    "#         'SVR': SVR(),\n",
    "#         'XGBOOST': XGBRegressor(),\n",
    "#         'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "#     }\n",
    "\n",
    "#     if chosen_model.lower() == 'all':\n",
    "#         chosen_models = models.keys()\n",
    "#     else:\n",
    "#         chosen_models = [chosen_model.upper()]  # Capitalize input for case insensitivity\n",
    "\n",
    "#     eval_metrics = {}\n",
    "\n",
    "#     for model_name in chosen_models:\n",
    "#         if model_name not in models:\n",
    "#             print(f\"Model '{model_name}' not found. Skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         model = models[model_name]\n",
    "\n",
    "#         if model_name == 'Gradient Boosting':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'min_samples_leaf': [1, 2, 4],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'SVR':\n",
    "#             params = {\n",
    "#                 'C': [0.1, 1, 10],\n",
    "#                 'kernel': ['linear', 'rbf', 'poly'],\n",
    "#                 'gamma': ['scale', 'auto']\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'XGBoost':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         # For LSTM model\n",
    "#         elif model_name == 'LSTM':\n",
    "#             model.add(Dense(units=1))  # Add output layer\n",
    "#             model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#             X_train_array = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#             X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#             model.fit(X_train_array, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "#             # Save the trained LSTM model\n",
    "#             model_filename = f\"Model_ATOM/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             model.save(model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#             predictions = model.predict(X_test_array).flatten()\n",
    "\n",
    "#             # Calculate evaluation metrics\n",
    "#             mae = mean_absolute_error(y_test, predictions)\n",
    "#             mse = mean_squared_error(y_test, predictions)\n",
    "#             rmse = np.sqrt(mse)\n",
    "#             mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#             r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#             # Store evaluation metrics\n",
    "#             eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "#             continue  # Skip the rest of the loop for LSTM\n",
    "\n",
    "\n",
    "#         # For other models\n",
    "#         model.fit(X_train, y_train)  # Fit the model\n",
    "#         predictions = model.predict(X_test)\n",
    "#         # Calculate evaluation metrics\n",
    "#         mae = mean_absolute_error(y_test, predictions)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#         r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#         # Store evaluation metrics\n",
    "#         eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "        \n",
    "#         # Save the trained model\n",
    "#         if save_models:\n",
    "#             model_filename = f\"Model_ATOM/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             os.makedirs(os.path.dirname(model_filename), exist_ok=True)\n",
    "#             joblib.dump(model, model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#     # Display evaluation metrics\n",
    "#     for model_name, metrics in eval_metrics.items():\n",
    "#         print(f\"Evaluation metrics for {model_name}:\")\n",
    "#         for metric_name, value in metrics.items():\n",
    "#             print(f\"{metric_name}: {value}\")\n",
    "#         print()\n",
    "\n",
    "#     # Plot evaluation metrics\n",
    "#     if eval_metrics:\n",
    "#         # Plot evaluation metrics\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "#         metrics = list(eval_metrics.keys())\n",
    "#         mae_values = [eval_metrics[model]['MAE'] for model in metrics]  # Corrected access to values\n",
    "#         mse_values = [eval_metrics[model]['MSE'] for model in metrics]  # Corrected access to values\n",
    "#         rmse_values = [eval_metrics[model]['RMSE'] for model in metrics]  # Corrected access to values\n",
    "#         mape_values = [eval_metrics[model]['MAPE'] for model in metrics]  # Corrected access to values\n",
    "#         r2_values = [eval_metrics[model]['R2'] for model in metrics]  # Corrected access to values\n",
    "\n",
    "        \n",
    "#         bar_width = 0.15  # Increased bar width\n",
    "#         index = np.arange(len(metrics))\n",
    "\n",
    "#         bar1 = ax.bar(index - 2*bar_width, mae_values, bar_width, label='MAE')  # Adjusted positions for bars\n",
    "#         bar2 = ax.bar(index - bar_width, mse_values, bar_width, label='MSE')   # Adjusted positions for bars\n",
    "#         bar3 = ax.bar(index, rmse_values, bar_width, label='RMSE')              # Adjusted positions for bars\n",
    "#         # bar4 = ax.bar(index + bar_width, mape_values, bar_width, label='MAPE')  # Adjusted positions for bars\n",
    "\n",
    "#         ax.set_xlabel('Models')\n",
    "#         ax.set_ylabel('Metrics')\n",
    "#         ax.set_title(f'Evaluation Metrics for ATOM using {chosen_model.upper()} as the Models')\n",
    "#         ax.set_xticks(index)\n",
    "#         ax.set_xticklabels(metrics)\n",
    "#         ax.legend()\n",
    "\n",
    "#         # Annotate bars with values\n",
    "#         for bars in [bar1, bar2, bar3]:\n",
    "#             for bar in bars:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.annotate('{}'.format(round(height, 2)),\n",
    "#                             xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "#                             xytext=(0, 3),  # 3 points vertical offset\n",
    "#                             textcoords=\"offset points\",\n",
    "#                             ha='center', va='bottom')\n",
    "\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"No models were evaluated.\")\n",
    "\n",
    "\n",
    "# # Load the selected data from a CSV file\n",
    "# selected_data = pd.read_csv(\"Selected_coins.csv\", index_col='Date')\n",
    "# # Usage\n",
    "# print(\"Available models: Gradient Boosting, SVR, XGBoost, LSTM\")\n",
    "# chosen_model = input(\"Enter the model you want to evaluate (or type 'all' for all models): \").strip()\n",
    "# evaluate_models_ATOM(selected_data, chosen_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449dce0-54f6-40ba-9793-8d3acde442dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training the models with BTC-GBP  and saving\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from xgboost import XGBRegressor\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# def evaluate_models_BTC(selected_data, chosen_model='all', save_models=True):\n",
    "#     # Making a copy of the slice to ensure it's a separate object\n",
    "#     selected_data = selected_data.copy()\n",
    "\n",
    "#     for lag in range(1, 4):  # Adding lagged features for 1 to 3 days\n",
    "#         selected_data.loc[:, f'BTC-GBP_lag_{lag}'] = selected_data['BTC-GBP'].shift(lag)\n",
    "\n",
    "#     # Dropping rows with NaN values created due to shifting\n",
    "#     selected_data.dropna(inplace=True)\n",
    "\n",
    "#     # Features will be the lagged values, and the target will be the current BTC-GBP price\n",
    "#     features = [f'BTC-GBP_lag_{lag}' for lag in range(1, 4)]\n",
    "#     X = selected_data[features]\n",
    "#     y = selected_data['BTC-GBP']\n",
    "\n",
    "#     # Splitting the dataset into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize and train the models\n",
    "#     models = {\n",
    "#         'GRADIENT BOOSTING': GradientBoostingRegressor(),\n",
    "#         'SVR': SVR(),\n",
    "#         'XGBOOST': XGBRegressor(),\n",
    "#         'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "#     }\n",
    "\n",
    "#     if chosen_model.lower() == 'all':\n",
    "#         chosen_models = models.keys()\n",
    "#     else:\n",
    "#         chosen_models = [chosen_model.upper()]  # Capitalize input for case insensitivity\n",
    "\n",
    "#     eval_metrics = {}\n",
    "\n",
    "#     for model_name in chosen_models:\n",
    "#         if model_name not in models:\n",
    "#             print(f\"Model '{model_name}' not found. Skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         model = models[model_name]\n",
    "\n",
    "#         if model_name == 'Gradient Boosting':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'min_samples_leaf': [1, 2, 4],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'SVR':\n",
    "#             params = {\n",
    "#                 'C': [0.1, 1, 10],\n",
    "#                 'kernel': ['linear', 'rbf', 'poly'],\n",
    "#                 'gamma': ['scale', 'auto']\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'XGBoost':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "            \n",
    "#         # For LSTM model\n",
    "#         elif model_name == 'LSTM':\n",
    "#             model.add(Dense(units=1))  # Add output layer\n",
    "#             model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#             X_train_array = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#             X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#             model.fit(X_train_array, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "#             # Save the trained LSTM model\n",
    "#             model_filename = f\"Model_BTC/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             model.save(model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#             predictions = model.predict(X_test_array).flatten()\n",
    "\n",
    "#             # Calculate evaluation metrics\n",
    "#             mae = mean_absolute_error(y_test, predictions)\n",
    "#             mse = mean_squared_error(y_test, predictions)\n",
    "#             rmse = np.sqrt(mse)\n",
    "#             mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#             r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#             # Store evaluation metrics\n",
    "#             eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "#             continue  # Skip the rest of the loop for LSTM\n",
    "\n",
    "\n",
    "#         # For other models\n",
    "#         model.fit(X_train, y_train)  # Fit the model\n",
    "#         predictions = model.predict(X_test)\n",
    "#         # Calculate evaluation metrics\n",
    "#         mae = mean_absolute_error(y_test, predictions)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#         r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#         # Store evaluation metrics\n",
    "#         eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "        \n",
    "#         # Save the trained model\n",
    "#         if save_models:\n",
    "#             model_filename = f\"Model_BTC/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             os.makedirs(os.path.dirname(model_filename), exist_ok=True)\n",
    "#             joblib.dump(model, model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#     # Display evaluation metrics\n",
    "#     for model_name, metrics in eval_metrics.items():\n",
    "#         print(f\"Evaluation metrics for {model_name}:\")\n",
    "#         for metric_name, value in metrics.items():\n",
    "#             print(f\"{metric_name}: {value}\")\n",
    "#         print()\n",
    "\n",
    "#     # Plot evaluation metrics\n",
    "#     if eval_metrics:\n",
    "#         # Plot evaluation metrics\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "#         metrics = list(eval_metrics.keys())\n",
    "#         mae_values = [eval_metrics[model]['MAE'] for model in metrics]  # Corrected access to values\n",
    "#         mse_values = [eval_metrics[model]['MSE'] for model in metrics]  # Corrected access to values\n",
    "#         rmse_values = [eval_metrics[model]['RMSE'] for model in metrics]  # Corrected access to values\n",
    "#         mape_values = [eval_metrics[model]['MAPE'] for model in metrics]  # Corrected access to values\n",
    "#         r2_values = [eval_metrics[model]['R2'] for model in metrics]  # Corrected access to values\n",
    "\n",
    "        \n",
    "#         bar_width = 0.15  # Increased bar width\n",
    "#         index = np.arange(len(metrics))\n",
    "\n",
    "#         bar1 = ax.bar(index - 2*bar_width, mae_values, bar_width, label='MAE')  # Adjusted positions for bars\n",
    "#         bar2 = ax.bar(index - bar_width, mse_values, bar_width, label='MSE')   # Adjusted positions for bars\n",
    "#         bar3 = ax.bar(index, rmse_values, bar_width, label='RMSE')              # Adjusted positions for bars\n",
    "#         # bar4 = ax.bar(index + bar_width, mape_values, bar_width, label='MAPE')  # Adjusted positions for bars\n",
    "\n",
    "#         ax.set_xlabel('Models')\n",
    "#         ax.set_ylabel('Metrics')\n",
    "#         ax.set_title(f'Evaluation Metrics for BTC using {chosen_model.upper()} as the Models')\n",
    "#         ax.set_xticks(index)\n",
    "#         ax.set_xticklabels(metrics)\n",
    "#         ax.legend()\n",
    "\n",
    "#         # Annotate bars with values\n",
    "#         for bars in [bar1, bar2, bar3]:\n",
    "#             for bar in bars:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.annotate('{}'.format(round(height, 2)),\n",
    "#                             xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "#                             xytext=(0, 3),  # 3 points vertical offset\n",
    "#                             textcoords=\"offset points\",\n",
    "#                             ha='center', va='bottom')\n",
    "\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"No models were evaluated.\")\n",
    "\n",
    "# # Usage\n",
    "# print(\"Available models: Gradient Boosting, SVR, XGBoost, LSTM\")\n",
    "# chosen_model = input(\"Enter the model you want to evaluate (or type 'all' for all models): \").strip()\n",
    "# evaluate_models_BTC(selected_data, chosen_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fc3d3-a6cf-4ad6-84b7-8156de1d05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training the models with AXS and saving\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from xgboost import XGBRegressor\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# def evaluate_models_AXS(selected_data, chosen_model='all', save_models=True):\n",
    "#     # Making a copy of the slice to ensure it's a separate object\n",
    "#     selected_data = selected_data.copy()\n",
    "\n",
    "#     for lag in range(1, 4):  # Adding lagged features for 1 to 3 days\n",
    "#         selected_data.loc[:, f'AXS-GBP_lag_{lag}'] = selected_data['AXS-GBP'].shift(lag)\n",
    "\n",
    "#     # Dropping rows with NaN values created due to shifting\n",
    "#     selected_data.dropna(inplace=True)\n",
    "\n",
    "#     # Features will be the lagged values, and the target will be the current BTC-GBP price\n",
    "#     features = [f'AXS-GBP_lag_{lag}' for lag in range(1, 4)]\n",
    "#     X = selected_data[features]\n",
    "#     y = selected_data['AXS-GBP']\n",
    "\n",
    "#     # Splitting the dataset into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize and train the models\n",
    "#     models = {\n",
    "#         'GRADIENT BOOSTING': GradientBoostingRegressor(),\n",
    "#         'SVR': SVR(),\n",
    "#         'XGBOOST': XGBRegressor(),\n",
    "#         'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "#     }\n",
    "\n",
    "#     if chosen_model.lower() == 'all':\n",
    "#         chosen_models = models.keys()\n",
    "#     else:\n",
    "#         chosen_models = [chosen_model.upper()]  # Capitalize input for case insensitivity\n",
    "\n",
    "#     eval_metrics = {}\n",
    "\n",
    "#     for model_name in chosen_models:\n",
    "#         if model_name not in models:\n",
    "#             print(f\"Model '{model_name}' not found. Skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         model = models[model_name]\n",
    "\n",
    "#         if model_name == 'Gradient Boosting':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'min_samples_leaf': [1, 2, 4],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'SVR':\n",
    "#             params = {\n",
    "#                 'C': [0.1, 1, 10],\n",
    "#                 'kernel': ['linear', 'rbf', 'poly'],\n",
    "#                 'gamma': ['scale', 'auto']\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'XGBoost':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         # For LSTM model\n",
    "#         elif model_name == 'LSTM':\n",
    "#             model.add(Dense(units=1))  # Add output layer\n",
    "#             model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#             X_train_array = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#             X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#             model.fit(X_train_array, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "#             # Save the trained LSTM model\n",
    "#             model_filename = f\"Model_AXS/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             model.save(model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#             predictions = model.predict(X_test_array).flatten()\n",
    "\n",
    "#             # Calculate evaluation metrics\n",
    "#             mae = mean_absolute_error(y_test, predictions)\n",
    "#             mse = mean_squared_error(y_test, predictions)\n",
    "#             rmse = np.sqrt(mse)\n",
    "#             mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#             r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#             # Store evaluation metrics\n",
    "#             eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "#             continue  # Skip the rest of the loop for LSTM\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "#         # For other models\n",
    "#         model.fit(X_train, y_train)  # Fit the model\n",
    "#         predictions = model.predict(X_test)\n",
    "#         # Calculate evaluation metrics\n",
    "#         mae = mean_absolute_error(y_test, predictions)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#         r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#         # Store evaluation metrics\n",
    "#         eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "        \n",
    "#          # Save the trained model\n",
    "#         if save_models:\n",
    "#             model_filename = f\"Model_AXS/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             os.makedirs(os.path.dirname(model_filename), exist_ok=True)\n",
    "#             joblib.dump(model, model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#     # Display evaluation metrics\n",
    "#     for model_name, metrics in eval_metrics.items():\n",
    "#         print(f\"Evaluation metrics for {model_name}:\")\n",
    "#         for metric_name, value in metrics.items():\n",
    "#             print(f\"{metric_name}: {value}\")\n",
    "#         print()\n",
    "\n",
    "#     # Plot evaluation metrics\n",
    "#     if eval_metrics:\n",
    "#         # Plot evaluation metrics\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "#         metrics = list(eval_metrics.keys())\n",
    "#         mae_values = [eval_metrics[model]['MAE'] for model in metrics]  # Corrected access to values\n",
    "#         mse_values = [eval_metrics[model]['MSE'] for model in metrics]  # Corrected access to values\n",
    "#         rmse_values = [eval_metrics[model]['RMSE'] for model in metrics]  # Corrected access to values\n",
    "#         mape_values = [eval_metrics[model]['MAPE'] for model in metrics]  # Corrected access to values\n",
    "#         r2_values = [eval_metrics[model]['R2'] for model in metrics]  # Corrected access to values\n",
    "\n",
    "        \n",
    "#         bar_width = 0.15  # Increased bar width\n",
    "#         index = np.arange(len(metrics))\n",
    "\n",
    "#         bar1 = ax.bar(index - 2*bar_width, mae_values, bar_width, label='MAE')  # Adjusted positions for bars\n",
    "#         bar2 = ax.bar(index - bar_width, mse_values, bar_width, label='MSE')   # Adjusted positions for bars\n",
    "#         bar3 = ax.bar(index, rmse_values, bar_width, label='RMSE')              # Adjusted positions for bars\n",
    "#         # bar4 = ax.bar(index + bar_width, mape_values, bar_width, label='MAPE')  # Adjusted positions for bars\n",
    "\n",
    "#         ax.set_xlabel('Models')\n",
    "#         ax.set_ylabel('Metrics')\n",
    "#         ax.set_title(f'Evaluation Metrics for AXS using {chosen_model.upper()} as the Models')\n",
    "#         ax.set_xticks(index)\n",
    "#         ax.set_xticklabels(metrics)\n",
    "#         ax.legend()\n",
    "\n",
    "#         # Annotate bars with values\n",
    "#         for bars in [bar1, bar2, bar3]:\n",
    "#             for bar in bars:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.annotate('{}'.format(round(height, 2)),\n",
    "#                             xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "#                             xytext=(0, 3),  # 3 points vertical offset\n",
    "#                             textcoords=\"offset points\",\n",
    "#                             ha='center', va='bottom')\n",
    "\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"No models were evaluated.\")\n",
    "\n",
    "# # Usage\n",
    "# print(\"Available models: Gradient Boosting, SVR, XGBoost, LSTM\")\n",
    "# chosen_model = input(\"Enter the model you want to evaluate (or type 'all' for all models): \").strip()\n",
    "# evaluate_models_AXS(selected_data, chosen_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37591ef9-f3bb-4aa6-b1f1-9c2b8d5e0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training the models with BCH and saving\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from xgboost import XGBRegressor\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# def evaluate_models_BCH(selected_data, chosen_model='all', save_models=True):\n",
    "#     # Making a copy of the slice to ensure it's a separate object\n",
    "#     selected_data = selected_data.copy()\n",
    "\n",
    "#     for lag in range(1, 4):  # Adding lagged features for 1 to 3 days\n",
    "#         selected_data.loc[:, f'BCH-GBP_lag_{lag}'] = selected_data['BCH-GBP'].shift(lag)\n",
    "\n",
    "#     # Dropping rows with NaN values created due to shifting\n",
    "#     selected_data.dropna(inplace=True)\n",
    "\n",
    "#     # Features will be the lagged values, and the target will be the current BTC-GBP price\n",
    "#     features = [f'BCH-GBP_lag_{lag}' for lag in range(1, 4)]\n",
    "#     X = selected_data[features]\n",
    "#     y = selected_data['BCH-GBP']\n",
    "\n",
    "#     # Splitting the dataset into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Initialize and train the models\n",
    "#     models = {\n",
    "#         'GRADIENT BOOSTING': GradientBoostingRegressor(),\n",
    "#         'SVR': SVR(),\n",
    "#         'XGBOOST': XGBRegressor(),\n",
    "#         'LSTM': Sequential([LSTM(units=50, input_shape=(X_train.shape[1], 1)), Dense(units=1)])\n",
    "#     }\n",
    "\n",
    "#     if chosen_model.lower() == 'all':\n",
    "#         chosen_models = models.keys()\n",
    "#     else:\n",
    "#         chosen_models = [chosen_model.upper()]  # Capitalize input for case insensitivity\n",
    "\n",
    "#     eval_metrics = {}\n",
    "\n",
    "#     for model_name in chosen_models:\n",
    "#         if model_name not in models:\n",
    "#             print(f\"Model '{model_name}' not found. Skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         model = models[model_name]\n",
    "\n",
    "#         if model_name == 'Gradient Boosting':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'min_samples_leaf': [1, 2, 4],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'SVR':\n",
    "#             params = {\n",
    "#                 'C': [0.1, 1, 10],\n",
    "#                 'kernel': ['linear', 'rbf', 'poly'],\n",
    "#                 'gamma': ['scale', 'auto']\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#         elif model_name == 'XGBoost':\n",
    "#             params = {\n",
    "#                 'n_estimators': [50, 100, 200],\n",
    "#                 'learning_rate': [0.01, 0.1, 0.5],\n",
    "#                 'max_depth': [3, 5, 7],\n",
    "#                 'subsample': [0.8, 0.9, 1.0]\n",
    "#             }\n",
    "#             model = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "#             model.fit(X_train, y_train)\n",
    "#             model = model.best_estimator_\n",
    "\n",
    "#             # For LSTM model\n",
    "#             # For LSTM model\n",
    "#         elif model_name == 'LSTM':\n",
    "#             model.add(Dense(units=1))  # Add output layer\n",
    "#             model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#             X_train_array = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#             X_test_array = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#             model.fit(X_train_array, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "#             # Save the trained LSTM model\n",
    "#             model_filename = f\"Model_BCH/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             model.save(model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#             predictions = model.predict(X_test_array).flatten()\n",
    "\n",
    "#             # Calculate evaluation metrics\n",
    "#             mae = mean_absolute_error(y_test, predictions)\n",
    "#             mse = mean_squared_error(y_test, predictions)\n",
    "#             rmse = np.sqrt(mse)\n",
    "#             mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#             r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#             # Store evaluation metrics\n",
    "#             eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "            \n",
    "#             continue  # Skip the rest of the loop for LSTM\n",
    "\n",
    "\n",
    "#         # For other models\n",
    "#         model.fit(X_train, y_train)  # Fit the model\n",
    "#         predictions = model.predict(X_test)\n",
    "#         # Calculate evaluation metrics\n",
    "#         mae = mean_absolute_error(y_test, predictions)\n",
    "#         mse = mean_squared_error(y_test, predictions)\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "#         r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#         # Store evaluation metrics\n",
    "#         eval_metrics[model_name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape, 'R2': r2}\n",
    "        \n",
    "#          # Save the trained model\n",
    "#         if save_models:\n",
    "#             model_filename = f\"Model_BCH/{model_name.lower().replace(' ', '_')}_model.pkl\"\n",
    "#             os.makedirs(os.path.dirname(model_filename), exist_ok=True)\n",
    "#             joblib.dump(model, model_filename)\n",
    "#             print(f\"Trained {model_name} model saved as {model_filename}\")\n",
    "\n",
    "#     # Display evaluation metrics\n",
    "#     for model_name, metrics in eval_metrics.items():\n",
    "#         print(f\"Evaluation metrics for {model_name}:\")\n",
    "#         for metric_name, value in metrics.items():\n",
    "#             print(f\"{metric_name}: {value}\")\n",
    "#         print()\n",
    "\n",
    "#     # Plot evaluation metrics\n",
    "#     if eval_metrics:\n",
    "#         # Plot evaluation metrics\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "#         metrics = list(eval_metrics.keys())\n",
    "#         mae_values = [eval_metrics[model]['MAE'] for model in metrics]  # Corrected access to values\n",
    "#         mse_values = [eval_metrics[model]['MSE'] for model in metrics]  # Corrected access to values\n",
    "#         rmse_values = [eval_metrics[model]['RMSE'] for model in metrics]  # Corrected access to values\n",
    "#         mape_values = [eval_metrics[model]['MAPE'] for model in metrics]  # Corrected access to values\n",
    "#         r2_values = [eval_metrics[model]['R2'] for model in metrics]  # Corrected access to values\n",
    "\n",
    "        \n",
    "#         bar_width = 0.15  # Increased bar width\n",
    "#         index = np.arange(len(metrics))\n",
    "\n",
    "#         bar1 = ax.bar(index - 2*bar_width, mae_values, bar_width, label='MAE')  # Adjusted positions for bars\n",
    "#         bar2 = ax.bar(index - bar_width, mse_values, bar_width, label='MSE')   # Adjusted positions for bars\n",
    "#         bar3 = ax.bar(index, rmse_values, bar_width, label='RMSE')              # Adjusted positions for bars\n",
    "#         # bar4 = ax.bar(index + bar_width, mape_values, bar_width, label='MAPE')  # Adjusted positions for bars\n",
    "\n",
    "#         ax.set_xlabel('Models')\n",
    "#         ax.set_ylabel('Metrics')\n",
    "#         ax.set_title(f'Evaluation Metrics for BCH using {chosen_model.upper()} as the Models')\n",
    "#         ax.set_xticks(index)\n",
    "#         ax.set_xticklabels(metrics)\n",
    "#         ax.legend()\n",
    "\n",
    "#         # Annotate bars with values\n",
    "#         for bars in [bar1, bar2, bar3]:\n",
    "#             for bar in bars:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.annotate('{}'.format(round(height, 2)),\n",
    "#                             xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "#                             xytext=(0, 3),  # 3 points vertical offset\n",
    "#                             textcoords=\"offset points\",\n",
    "#                             ha='center', va='bottom')\n",
    "\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"No models were evaluated.\")\n",
    "        \n",
    "    \n",
    "\n",
    "# # Usage\n",
    "# print(\"Available models: Gradient Boosting, SVR, XGBoost, LSTM\")\n",
    "# chosen_model = input(\"Enter the model you want to evaluate (or type 'all' for all models): \").strip()\n",
    "# evaluate_models_BCH(selected_data, chosen_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efba88-a682-42cd-8505-7311c96f6e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
