{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55dce584-48d5-40cd-b3c7-09a1b6dbf098",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\adedi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b50b55a-86fb-4383-a72e-578a09b3c3e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb84a19-94e1-421c-8cc8-021eca8ba01b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles scraped: 1\n",
      "Article 1:\n",
      "Headline: Dogwifhat Becomes Third-Largest Meme Coin as Bitcoin Clings to $70K\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_coindesk_news():\n",
    "    url = 'https://www.coindesk.com/'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Find all <h2> tags with the specified class names\n",
    "        headlines = soup.find_all('h2', class_='typography__StyledTypography-sc-owin6q-0 lhxPXi')\n",
    "        news = []\n",
    "        for headline in headlines:\n",
    "            news.append({\n",
    "                'headline': headline.text.strip()\n",
    "            })\n",
    "        return news\n",
    "    else:\n",
    "        print(f\"Error fetching news: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    news = scrape_coindesk_news()\n",
    "    if news:\n",
    "        print(f\"Number of articles scraped: {len(news)}\")\n",
    "        for idx, article in enumerate(news, start=1):\n",
    "            print(f\"Article {idx}:\")\n",
    "            print(f\"Headline: {article['headline']}\")\n",
    "            print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7ebe8-dd64-4255-855f-2d9a8d733573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "799bd772-dd83-4578-9e69-a4d4e53f951b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped headlines:\n",
      "1. Dogwifhat Becomes Third-Largest Meme Coin as Bitcoin Clings to $70K\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to scrape cryptocurrency news headlines from CoinDesk\n",
    "def scrape_coindesk_news():\n",
    "    url = 'https://www.coindesk.com/'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        headline_elements = soup.find_all('h2', class_='typography__StyledTypography-sc-owin6q-0 lhxPXi')\n",
    "        headlines = [headline.text.strip() for headline in headline_elements]\n",
    "        if not headlines:\n",
    "            print(\"No headlines found. Please check the website structure.\")\n",
    "        return headlines\n",
    "    else:\n",
    "        print(f\"Error fetching news: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    news_headlines = scrape_coindesk_news()\n",
    "    if news_headlines:\n",
    "        print(\"Scraped headlines:\")\n",
    "        for idx, headline in enumerate(news_headlines, start=1):\n",
    "            print(f\"{idx}. {headline}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b130fc-554f-4dd8-b53a-b312d259916f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_key = 'iXpfKD83ZsSptN2fgO0b5k5nN'\n",
    "API_secret = '7qVRLQAm7mL7c41DD6lGMp5ww1oebz2BetsmW4I1wIF6gaFt85'\n",
    "Access_token = '1053190298271145984-g4Az9vk4FmxnwUhlAiZY71yj83esB2'\n",
    "Access_secret = 'ECu5tZ04dmZ1FyhbyOy0euk1mUXEXPIN5xY95B0IGULQP'\n",
    "\n",
    "\n",
    "# From Tweepy docs\n",
    "auth = tweepy.OAuthHandler(API_key, API_secret)\n",
    "auth.set_access_token(Access_token, Access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fcf12ac-2892-420b-b8d3-0aa57c920753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define Variables\n",
    "# count = 10\n",
    "# coinid = '£ETHGBP'\n",
    "\n",
    "# #Clean up collected tweets with regex\n",
    "# def nice_tweet(tweet):\n",
    "#        return' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af618037-b2d2-4428-afd4-4e72d146099a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_tweets(coinid, count):\n",
    "#     tweets = set()\n",
    "#     collected_tweets = api.search(q = coinid, count = count)\n",
    "#     for tweet in collected_tweets:\n",
    "#         cleaned_tweet = clean_tweet(tweet.text)\n",
    "#         if cleaned_tweet not in tweets:\n",
    "#             tweets.add(cleaned_tweet)\n",
    "#     return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8afcfdaa-6af7-4baf-89c9-2e57056bdb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def polarity(tweets):\n",
    "#     scores = []\n",
    "#     for tweet in tweets:\n",
    "#         score = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
    "#         score['tweet'] = tweet\n",
    "#         scores.append(score)\n",
    "#     return scores\n",
    "\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f7a7629-4653-49fe-b287-44cc26620d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tweepy\n",
    "\n",
    "# # # Twitter API credentials\n",
    "# # API_key = 'your_api_key'\n",
    "# # API_secret = 'your_api_secret'\n",
    "# # Access_token = 'your_access_token'\n",
    "# # Access_secret = 'your_access_secret'\n",
    "\n",
    "# # Tweepy authentication\n",
    "# auth = tweepy.OAuthHandler(API_key, API_secret)\n",
    "# auth.set_access_token(Access_token, Access_secret)\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "# # Function to fetch engagement data for a given hashtag\n",
    "# def get_engagement_data(hashtag, count=10):\n",
    "#     tweets = api.search_tweets(q=hashtag, count=count)\n",
    "#     engagement_data = []\n",
    "#     for tweet in tweets:\n",
    "#         engagement_data.append({\n",
    "#             'text': tweet.text,\n",
    "#             'likes': tweet.favorite_count,\n",
    "#             'retweets': tweet.retweet_count,\n",
    "#             'replies': tweet.reply_count\n",
    "#         })\n",
    "#     return engagement_data\n",
    "\n",
    "# # Function to fetch trending topics\n",
    "# def get_trending_topics():\n",
    "#     trending_topics = api.trends_place(id=1)\n",
    "#     return [trend['name'] for trend in trending_topics[0]['trends']]\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     hashtag = '#crypto'\n",
    "#     engagement_data = get_engagement_data(hashtag)\n",
    "#     print(f\"Engagement data for hashtag {hashtag}:\")\n",
    "#     for tweet in engagement_data:\n",
    "#         print(f\"Text: {tweet['text']}\")\n",
    "#         print(f\"Likes: {tweet['likes']}, Retweets: {tweet['retweets']}, Replies: {tweet['replies']}\")\n",
    "#         print(\"---\")\n",
    "    \n",
    "#     trending_topics = get_trending_topics()\n",
    "#     print(\"\\nTrending topics:\")\n",
    "#     for topic in trending_topics:\n",
    "#         print(topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4882d19e-305d-4348-9369-7ff8e6a5e18e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# API_key = 'iXpfKD83ZsSptN2fgO0b5k5nN'\n",
    "# API_secret = '7qVRLQAm7mL7c41DD6lGMp5ww1oebz2BetsmW4I1wIF6gaFt85'\n",
    "# Access_token = '1053190298271145984-g4Az9vk4FmxnwUhlAiZY71yj83esB2'\n",
    "# Access_secret = 'ECu5tZ04dmZ1FyhbyOy0euk1mUXEXPIN5xY95B0IGULQP'\n",
    "\n",
    "\n",
    "# # From Tweepy docs\n",
    "# auth = tweepy.OAuthHandler(API_key, API_secret)\n",
    "# auth.set_access_token(Access_token, Access_secret)\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "# # Twitter API v2 Bearer Token\n",
    "# bearer_token = 'AAAAAAAAAAAAAAAAAAAAAClhtAEAAAAAMnXf1bSSTGFISinS%2F8qtZnmwxFc%3DXkQTzV6lGQvyfos9yow2NiKBfFBVia6646UHmAYmgPDctL2jb4'\n",
    "\n",
    "# # Function to fetch recent tweets for a given hashtag\n",
    "# def get_recent_tweets(hashtag, max_results=10):\n",
    "#     url = f'https://api.twitter.com/2/tweets/search/recent?query={hashtag}&max_results={max_results}'\n",
    "#     headers = {'Authorization': f'Bearer {bearer_token}'}\n",
    "#     response = requests.get(url, headers=headers)\n",
    "#     if response.status_code == 200:\n",
    "#         return response.json()\n",
    "#     else:\n",
    "#         print(f\"Error fetching tweets: {response.text}\")\n",
    "#         return None\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     hashtag = '%23crypto'  # URL encoded format for '#crypto'\n",
    "#     recent_tweets = get_recent_tweets(hashtag)\n",
    "#     if recent_tweets:\n",
    "#         for tweet in recent_tweets['data']:\n",
    "#             print(f\"Text: {tweet['text']}\")\n",
    "#             print(f\"Likes: {tweet['public_metrics']['like_count']}, Retweets: {tweet['public_metrics']['retweet_count']}\")\n",
    "#             print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c582690-b68e-4b03-b388-ca28ef06c655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tweepy\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "# import nltk\n",
    "# from datetime import datetime\n",
    "\n",
    "# # # Ensure you have the VADER lexicon downloaded\n",
    "# # nltk.download('vader_lexicon')\n",
    "\n",
    "# # # Twitter API credentials\n",
    "# # API_key = 'your_api_key'\n",
    "# # API_secret = 'your_api_secret'\n",
    "# # Access_token = 'your_access_token'\n",
    "# # Access_secret = 'your_access_secret'\n",
    "\n",
    "# # # Tweepy authentication\n",
    "# # auth = tweepy.OAuthHandler(API_key, API_secret)\n",
    "# # auth.set_access_token(Access_token, Access_secret)\n",
    "# # api = tweepy.API(auth)\n",
    "\n",
    "# # Define Variables\n",
    "# count = 10\n",
    "# coinid = '£ETHGBP'\n",
    "\n",
    "# # Track monthly post count\n",
    "# def get_monthly_post_count():\n",
    "#     # Implement a mechanism to track the number of posts made in the current month\n",
    "#     # This could involve storing the count in a file, database, or memory\n",
    "#     # For simplicity, we'll use a dictionary to store the count in memory\n",
    "#     # Initialize the count to 0 if it's a new month\n",
    "#     current_month = datetime.now().strftime('%Y-%m')\n",
    "#     if current_month not in monthly_post_count:\n",
    "#         monthly_post_count[current_month] = 0\n",
    "#     return monthly_post_count[current_month]\n",
    "\n",
    "# # Clean up collected tweets with regex\n",
    "# def clean_tweet(tweet):\n",
    "#     return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "# # Function to get and clean tweets\n",
    "# def get_tweets(coinid, count):\n",
    "#     tweets = set()\n",
    "#     collected_tweets = api.search_tweets(q=coinid, count=count)  # Updated method name to search_tweets\n",
    "#     for tweet in collected_tweets:\n",
    "#         cleaned_tweet = clean_tweet(tweet.text)\n",
    "#         if cleaned_tweet not in tweets:\n",
    "#             tweets.add(cleaned_tweet)\n",
    "#     return tweets\n",
    "\n",
    "# # Analyze sentiment polarity of tweets\n",
    "# def polarity(tweets):\n",
    "#     scores = []\n",
    "#     analyzer = SentimentIntensityAnalyzer()\n",
    "#     for tweet in tweets:\n",
    "#         score = analyzer.polarity_scores(tweet)\n",
    "#         score['tweet'] = tweet\n",
    "#         scores.append(score)\n",
    "#     return scores\n",
    "\n",
    "# # Initialize monthly post count dictionary\n",
    "# monthly_post_count = {}\n",
    "\n",
    "# # Get monthly post count\n",
    "# current_monthly_post_count = get_monthly_post_count()\n",
    "\n",
    "# # Check if the limit is reached before fetching tweets\n",
    "# if current_monthly_post_count >= 1500:\n",
    "#     print(\"Monthly post limit reached. Cannot fetch more tweets.\")\n",
    "# else:\n",
    "#     # Get tweets\n",
    "#     tweets = get_tweets(coinid, count)\n",
    "    \n",
    "#     # Get sentiment scores\n",
    "#     scores = polarity(tweets)\n",
    "    \n",
    "#     # Update monthly post count\n",
    "#     monthly_post_count[datetime.now().strftime('%Y-%m')] += len(tweets)\n",
    "    \n",
    "#     # Convert to DataFrame\n",
    "#     df = pd.DataFrame(scores)\n",
    "    \n",
    "#     # Print DataFrame\n",
    "#     print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d3f9fce-4e2f-45a3-816f-f4d67ccc3e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #From Tweepy docs\n",
    "# auth = tweepy.OAuthHandler(API_key, API_secret)\n",
    "# auth.set_access_token(Access_token, Access_secret)\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "# # Define Variables\n",
    "# count = 10\n",
    "# coinid = '£ETHGBP'\n",
    "\n",
    "# #Clean up collected tweets with regex\n",
    "# def nice_tweet(tweet):\n",
    "#        return' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "    \n",
    "    \n",
    "# def get_tweets(coinid, count):\n",
    "#     tweets = set()\n",
    "#     collected_tweets = api.search(q = coinid, count = count)\n",
    "#     for tweet in collected_tweets:\n",
    "#         cleaned_tweet = clean_tweet(tweet.text)\n",
    "#         if cleaned_tweet not in tweets:\n",
    "#             tweets.add(cleaned_tweet)\n",
    "#     return tweets\n",
    "\n",
    "\n",
    "# def polarity(tweets):\n",
    "#     scores = []\n",
    "#     for tweet in tweets:\n",
    "#         score = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
    "#         score['tweet'] = tweet\n",
    "#         scores.append(score)\n",
    "#     return scores\n",
    "\n",
    "# print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
