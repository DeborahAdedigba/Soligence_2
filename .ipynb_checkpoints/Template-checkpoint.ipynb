{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca6beb-27e7-42f7-b916-0ec40c523478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "# Function to fetch cryptocurrency data from a data source (e.g., API)\n",
    "def fetch_cryptocurrency_data(symbol, interval='daily', num_periods=365):\n",
    "    # Implement code to fetch cryptocurrency data from a data source (e.g., API)\n",
    "    # Ensure the data is in the required format (e.g., DataFrame with columns: timestamp, open, close, high, low)\n",
    "    # Example:\n",
    "    # data = requests.get(api_url).json()\n",
    "    # df = pd.DataFrame(data)\n",
    "    # df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    # df.set_index('timestamp', inplace=True)\n",
    "    # return df\n",
    "\n",
    "# Function to display a graphical representation of cryptocurrency price over a specified interval\n",
    "def plot_price_over_interval(df, interval='daily'):\n",
    "    # Implement code to plot cryptocurrency price over the specified interval\n",
    "    # Example:\n",
    "    # plt.plot(df.index, df['close'])\n",
    "    # plt.xlabel('Date')\n",
    "    # plt.ylabel('Price')\n",
    "    # plt.title('Cryptocurrency Price Over Time')\n",
    "    # plt.show()\n",
    "\n",
    "# Function to identify correlated cryptocurrencies for a chosen coin\n",
    "def find_correlated_cryptocurrencies(df, coin_symbol):\n",
    "    # Implement code to find positively and negatively correlated cryptocurrencies for the chosen coin\n",
    "    # Example:\n",
    "    # correlations = df.corr()\n",
    "    # correlated_coins = correlations[coin_symbol].sort_values(ascending=False)\n",
    "    # return correlated_coins\n",
    "\n",
    "# Function to calculate moving average of a chosen cryptocurrency\n",
    "def calculate_moving_average(df, window=30):\n",
    "    # Implement code to calculate the moving average of the chosen cryptocurrency\n",
    "    # Example:\n",
    "    # moving_avg = df['close'].rolling(window=window).mean()\n",
    "    # return moving_avg\n",
    "\n",
    "# Function to train a machine learning model for cryptocurrency price prediction\n",
    "def train_model(df):\n",
    "    # Implement code to preprocess data, split into training and testing sets, and train a machine learning model\n",
    "    # Example:\n",
    "    # X = df[['feature1', 'feature2', ...]]\n",
    "    # y = df['close']\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # model = RandomForestRegressor()\n",
    "    # model.fit(X_train, y_train)\n",
    "    # return model\n",
    "\n",
    "# Function to predict possible high and low of a chosen cryptocurrency\n",
    "def predict_high_low(model, df):\n",
    "    # Implement code to use the trained model to predict possible high and low of the chosen cryptocurrency\n",
    "    # Example:\n",
    "    # predictions = model.predict(X_test)\n",
    "    # high = predictions.max()\n",
    "    # low = predictions.min()\n",
    "    # return high, low\n",
    "\n",
    "# Function to determine best time to buy and sell a chosen cryptocurrency\n",
    "def determine_best_time_to_trade(model, df):\n",
    "    # Implement code to determine the best time to buy and sell the chosen cryptocurrency for maximum profit\n",
    "    # Example:\n",
    "    # Implement your trading strategy using the trained model and historical data\n",
    "    # Return the best time to buy and sell and the anticipated amount of profit/loss\n",
    "\n",
    "# Function to predict market state of chosen cryptocurrencies\n",
    "def predict_market_state(model, df):\n",
    "    # Implement code to predict the market state of chosen cryptocurrencies (e.g., bullish or bearish)\n",
    "    # Example:\n",
    "    # Implement your market prediction strategy using the trained model and historical data\n",
    "    # Return the predicted market state\n",
    "\n",
    "# Function to calculate confidence level of predicted values\n",
    "def calculate_confidence_level(model, X_test, y_test):\n",
    "    # Implement code to calculate the confidence level (e.g., accuracy) of predicted values\n",
    "    # Example:\n",
    "    # predictions = model.predict(X_test)\n",
    "    # mse = mean_squared_error(y_test, predictions)\n",
    "    # confidence_level = 1 - mse\n",
    "    # return confidence_level\n",
    "\n",
    "# Function to fetch top stories or RSS feed about specific cryptocurrencies\n",
    "def fetch_top_stories(symbol):\n",
    "    # Implement code to fetch top stories or RSS feed about specific cryptocurrencies\n",
    "    # Example:\n",
    "    # Use web scraping or API to fetch relevant news articles or updates about the chosen cryptocurrency\n",
    "    # Return the top stories\n",
    "\n",
    "# Main function to orchestrate the system\n",
    "def main():\n",
    "    # Fetch cryptocurrency data for a chosen symbol\n",
    "    symbol = 'BTC'\n",
    "    df = fetch_cryptocurrency_data(symbol)\n",
    "\n",
    "    # Display a graphical representation of cryptocurrency price over a specified interval\n",
    "    plot_price_over_interval(df)\n",
    "\n",
    "    # Identify correlated cryptocurrencies for the chosen coin\n",
    "    correlated_coins = find_correlated_cryptocurrencies(df, symbol)\n",
    "\n",
    "    # Calculate moving average of the chosen cryptocurrency\n",
    "    moving_avg = calculate_moving_average(df)\n",
    "\n",
    "    # Train a machine learning model for cryptocurrency price prediction\n",
    "    model = train_model(df)\n",
    "\n",
    "    # Predict possible high and low of the chosen cryptocurrency\n",
    "    high, low = predict_high_low(model, df)\n",
    "\n",
    "    # Determine best time to buy and sell the chosen cryptocurrency\n",
    "    best_time_to_trade = determine_best_time_to_trade(model, df)\n",
    "\n",
    "    # Predict market state of chosen cryptocurrencies\n",
    "    market_state = predict_market_state(model, df)\n",
    "\n",
    "    # Calculate confidence level of predicted values\n",
    "    confidence_level = calculate_confidence_level(model, X_test, y_test)\n",
    "\n",
    "    # Fetch top stories or RSS feed about specific cryptocurrencies\n",
    "    top_stories = fetch_top_stories(symbol)\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fd199-406d-4b06-91e4-f7baaef7a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ardi_data = pd.read_csv('Alcohol-Related_Disease_Impact__ARDI__Application_-_Alcohol-Attributable_Deaths_20240217.csv')\n",
    "# ardi_data.head()\n",
    "# ardi_data.shape\n",
    "# missing_values = ardi_data.isnull().sum()\n",
    "\n",
    "# missing_values\n",
    "\n",
    "# # Check for zero values\n",
    "# zero_values = ardi_data[ardi_data['Data_Value_Alt'] == 0]\n",
    "\n",
    "# # Check for empty cells (NaN or None)\n",
    "# empty_cells = ardi_data[ardi_data['Data_Value_Alt'].isnull() | (ardi_data['Data_Value_Alt'] == '')]\n",
    "\n",
    "# # # Display the rows with zero values and empty cells\n",
    "# # print(\"Rows with zero values:\")\n",
    "# # print(zero_values)\n",
    "\n",
    "# # print(\"\\nRows with empty cells:\")\n",
    "# # print(empty_cells)\n",
    "\n",
    "# # Check for negative values\n",
    "# negative_values = ardi_data[ardi_data['Data_Value_Alt'] < 0]\n",
    "\n",
    "# # Display rows with negative values\n",
    "# print(\"Rows with negative values:\")\n",
    "# # print(negative_values)\n",
    "\n",
    "# # Drop rows with negative values\n",
    "# ardi_data = ardi_data[ardi_data['Data_Value_Alt'] >= 0]\n",
    "\n",
    "# ardi_data.shape\n",
    "\n",
    "# # Drop rows with empty cells (NaN or None) in the 'Data_value' column the target variable\n",
    "# ardi_data = ardi_data.dropna(subset=['Data_Value_Alt'])\n",
    "\n",
    "# ardi_data.isnull().sum()\n",
    "\n",
    "# # ardi_data.to_csv(\"new_try.csv\")\n",
    "\n",
    "# # Check for zero values\n",
    "# zero_values = ardi_data[ardi_data['Data_Value_Alt'] == 0].count()\n",
    "\n",
    "# # Display rows with zero values\n",
    "# print(\"Rows with zero values:\")\n",
    "# print(zero_values)\n",
    "\n",
    "# ardi_data.shape\n",
    "\n",
    "\n",
    "# ardi_data.info()\n",
    "\n",
    "# # Convert start year and end year to date as years alone\n",
    "# ardi_data['YearStart'] = pd.to_datetime(ardi_data['YearStart'], format='%Y').dt.year\n",
    "# ardi_data['YearEnd'] = pd.to_datetime(ardi_data['YearEnd'], format='%Y').dt.year\n",
    "\n",
    "# # Verify the changes\n",
    "# print(ardi_data.dtypes)\n",
    "\n",
    "# # Check the unique values in the 'AgeGroup_New' column\n",
    "# unique_age_groups = ardi_data['AgeGroup'].unique()\n",
    "\n",
    "# # Print the unique age groups\n",
    "# print(unique_age_groups)\n",
    "\n",
    "# # Define a mapping dictionary to map each age group to its corresponding category\n",
    "# age_group_mapping = {\n",
    "#     'Under 21': 'Under 21',\n",
    "#     '0-19': 'Under 21',    # Merged '0-19' with 'Under 21'\n",
    "#     '20-34': '21-34',\n",
    "#     '35-49': '35-49',\n",
    "#     '50-64': '50-64',\n",
    "#     '65+': '65 and older',  # Changed '65+' to '61 and older' to match the specified category\n",
    "#     'Overall': 'Overall'\n",
    "# }\n",
    "\n",
    "# # Map the age group strings to their corresponding categories using the mapping dictionary\n",
    "# ardi_data['AgeGroup_Cat'] = ardi_data['AgeGroup'].map(age_group_mapping)\n",
    "\n",
    "# # Display the unique values in the new column to verify the categorization\n",
    "# print(ardi_data['AgeGroup_Cat'].unique())\n",
    "\n",
    "# ardi_data\n",
    "\n",
    "\n",
    "# # dropping the added encoding the data \n",
    "# ardi_data_c = ardi_data.copy()\n",
    "# ardi_data_c = ardi_data_c[['YearStart', 'YearEnd', 'LocationAbbr', 'LocationDesc', 'DataSource', 'ConditionType',\n",
    "#          'Category', 'Cause_of_Death', 'Data_Value_Unit', 'Data_Value_Type', 'Data_Value',\n",
    "#          'Data_Value_Alt', 'Data_Value_Footnote_Symbol', 'Data_Value_Footnote', 'Effect',\n",
    "#          'ConsumptionPattern', 'Sex', 'AgeGroup', 'AgeGroup_Cat']]\n",
    "\n",
    "# # Drop specified columns\n",
    "# ardi_data_c.drop(['Data_Value_Unit', 'Data_Value_Type', 'Data_Value', 'Data_Value_Footnote_Symbol', 'Data_Value_Footnote'], axis=1, inplace=True)\n",
    "# # Drop rows where LocationDesc is 'United States'\n",
    "# ardi_data_c = ardi_data_c[ardi_data_c['LocationDesc'] != 'United States']\n",
    "\n",
    "# ardi_data_c \n",
    "# ardi_data_c.to_csv(\"Cleaned_1_data.csv\",index=False)\n",
    "\n",
    "\n",
    "# \"\"\"Log transformation is particularly effective for right-skewed data, as it compresses larger values more than smaller ones.\n",
    "# This helps to spread out the data and make the distribution more symmetric.\n",
    "# Log transformation is commonly used in health data analysis, especially for variables such as income, \n",
    "# biomarker measurements, or other health-related indicators.\"\"\"\n",
    "\n",
    "\n",
    "# # Example dataset with outliers\n",
    "# data = ardi_data_c['Data_Value_Alt']\n",
    "\n",
    "# # Apply log transformation\n",
    "# transformed_data = np.log(ardi_data_c['Data_Value_Alt'])\n",
    "\n",
    "# # Plot boxplots for original and transformed data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.boxplot(data)\n",
    "# plt.title('Original Data')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.boxplot(transformed_data)\n",
    "# plt.title('Transformed Data (Log Scale)')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# ardi_data_c.describe()\n",
    "\n",
    "# # Group the data by 'Sex' and calculate the total number of deaths\n",
    "# total_deaths_by_sex = ardi_data_c.groupby('Sex')['Data_Value_Alt'].sum()\n",
    "\n",
    "# # Create a pie chart\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.pie(total_deaths_by_sex, labels=total_deaths_by_sex.index, autopct='%1.1f%%', startangle=140)\n",
    "# plt.title('Total Number of Deaths by Sex (2015-2019)')\n",
    "# plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# # Assuming ardi_data_c is your DataFrame and already imported\n",
    "\n",
    "# # Grouping and summing data\n",
    "# total_deaths_by_type = ardi_data_c.groupby('ConditionType')['Data_Value_Alt'].sum().reset_index()\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# # Now you can directly use total_deaths_by_type as it's correctly formatted\n",
    "# ax = sns.barplot(x='ConditionType', y='Data_Value_Alt', data=total_deaths_by_type, palette='viridis')\n",
    "# plt.title('Number of Deaths by Condition for United States')\n",
    "# plt.xlabel('Stages')\n",
    "# plt.ylabel('Number of Deaths')\n",
    "# plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "\n",
    "# # Correcting the annotation loop\n",
    "# # Note: Adjust the \"+ 10\" in the y parameter if the annotations don't fit well visually\n",
    "# for i, (condition, total) in enumerate(zip(total_deaths_by_type['ConditionType'], total_deaths_by_type['Data_Value_Alt'])):\n",
    "#     plt.text(i, total + 10, str(round(total, 2)), ha='center', va='bottom', rotation=45)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Filter out the row with state name 'United States'\n",
    "# data_filtered = ardi_data_c[ardi_data_c['LocationDesc'] != 'United States']\n",
    "\n",
    "# # Group data by state and sum the number of deaths\n",
    "# deaths_by_state = data_filtered.groupby('LocationDesc')['Data_Value_Alt'].sum().reset_index()\n",
    "\n",
    "# # Sorting the data by the number of deaths\n",
    "# deaths_by_state = deaths_by_state.sort_values(by='Data_Value_Alt', ascending=False)\n",
    "\n",
    "# # Plotting the bar chart\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# ax = sns.barplot(x='LocationDesc', y='Data_Value_Alt', data=deaths_by_state, palette='viridis')\n",
    "# plt.title('Number of Deaths by State for United States')\n",
    "# plt.xlabel('State')\n",
    "# plt.ylabel('Number of Deaths')\n",
    "# plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "\n",
    "# # Add annotation in interval of 2 bins\n",
    "# for i in range(0, len(deaths_by_state), 2):\n",
    "#     plt.text(i, deaths_by_state.iloc[i]['Data_Value_Alt'] + 10, str(deaths_by_state.iloc[i]['Data_Value_Alt']), ha='center', va='bottom', rotation=45)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8977a-55e0-42f9-8b21-53dd53c75f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ardi_data = pd.read_csv(\"Cleaned_1_data.csv\")\n",
    "\n",
    "ardi_data\n",
    "\n",
    "# Age based 1\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Load the dataset from ardi_data\n",
    "# df = pd.read_csv('ardi_data.csv')\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['LocationAbbr','Sex', 'ConditionType', 'Category','Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on AgeGroup using SVR\n",
    "def predict_by_agegroup_svr(age_group):\n",
    "    df_filtered = ardi_data[ardi_data['AgeGroup'] == age_group]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['LocationAbbr','Sex', 'ConditionType', 'Category','Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    model = SVR(kernel='linear')  # Using a linear kernel for SVR\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "#     model = SVR(kernel='rbf')  # Using RBF kernel for SVR\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     # Make predictions\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "    svr_mse = mean_squared_error(y_test, y_pred)\n",
    "    svr_mae = mean_absolute_error(y_test, y_pred)\n",
    "    svr_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, svr_mse, svr_mae, svr_r2\n",
    "\n",
    "# Example prediction using SVR based on AgeGroup\n",
    "age_group = 'Under 21'\n",
    "\n",
    "prediction, svr_mse, svr_mae, svr_r2 = predict_by_agegroup_svr(age_group)\n",
    "print(f\"SVR Predicted values for '{age_group}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", svr_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", svr_mae)\n",
    "print(\"R-squared (R2):\", svr_r2)\n",
    "\n",
    "\n",
    "# Age based 2\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Load the dataset from ardi_data\n",
    "# df = pd.read_csv('ardi_data.csv')\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['LocationAbbr','Sex', 'ConditionType', 'Category','Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on AgeGroup using Gradient Boosting\n",
    "def predict_by_agegroup_gb(age_group):\n",
    "    df_filtered = ardi_data[ardi_data['AgeGroup'] == age_group]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['LocationAbbr','Sex', 'ConditionType', 'Category','Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    model = GradientBoostingRegressor()  # Using Gradient Boosting for regression\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, mse, mae, r2\n",
    "\n",
    "# Example prediction using Gradient Boosting based on AgeGroup\n",
    "age_group = 'Under 21'\n",
    "\n",
    "prediction, mse, mae, r2 = predict_by_agegroup_gb(age_group)\n",
    "print(f\"Gradient Boosting Predicted values for '{age_group}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared (R2):\", r2)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['LocationAbbr','Sex', 'ConditionType', 'Category','Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on AgeGroup using XGBoost\n",
    "def predict_by_agegroup_xgb(age_group):\n",
    "    df_filtered = ardi_data[ardi_data['AgeGroup'] == age_group]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['LocationAbbr','Sex', 'ConditionType', 'Category','Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    model = XGBRegressor()  # Using XGBoost for regression\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    xgboost_mse = mean_squared_error(y_test, y_pred)\n",
    "    xgboost_mae = mean_absolute_error(y_test, y_pred)\n",
    "    xgboost_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, xgboost_mse, xgboost_mae, xgboost_r2\n",
    "\n",
    "# Example prediction using XGBoost based on AgeGroup\n",
    "age_group = 'Under 21'\n",
    "\n",
    "prediction, xgboost_mse, xgboost_mae, xgboost_r2 = predict_by_agegroup_xgb(age_group)\n",
    "print(f\"XGBoost Predicted values for '{age_group}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", xgboost_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", xgboost_mae)\n",
    "print(\"R-squared (R2):\", xgboost_r2)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['LocationAbbr', 'Sex', 'ConditionType', 'Category', 'Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on AgeGroup using Random Forest\n",
    "def predict_by_agegroup_rf(age_group):\n",
    "    df_filtered = ardi_data[ardi_data['AgeGroup'] == age_group]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['LocationAbbr', 'Sex', 'ConditionType', 'Category', 'Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RandomForestRegressor()  # Using RandomForestRegressor for regression\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    rf_mse = mean_squared_error(y_test, y_pred)\n",
    "    rf_mae = mean_absolute_error(y_test, y_pred)\n",
    "    rf_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, rf_mse, rf_mae, rf_r2\n",
    "\n",
    "# Example prediction using Random Forest based on AgeGroup\n",
    "age_group = 'Under 21'\n",
    "\n",
    "prediction, rf_mse, rf_mae, rf_r2 = predict_by_agegroup_rf(age_group)\n",
    "print(f\"Random Forest Predicted values for '{age_group}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", rf_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", rf_mae)\n",
    "print(\"R-squared (R2):\", rf_r2)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a list of model names and their respective metrics\n",
    "models = ['Linear Regression', 'XGBoost', 'SVR', 'RandomForest']\n",
    "mse_scores = [linear_mse, xgboost_mse, svr_mse, rf_mse]\n",
    "mae_scores = [linear_mae, xgboost_mae, svr_mae,rf_mae]\n",
    "r2_scores = [linear_r2, xgboost_r2, svr_r2,rf_r2]\n",
    "\n",
    "# Plot Mean Squared Error (MSE)\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(models, mse_scores, color='blue')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Comparison of Mean Squared Error (MSE) among Models using Location')\n",
    "\n",
    "# Add annotations to the bars\n",
    "for bar, mse in zip(bars, mse_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{mse:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot Mean Absolute Error (MAE)\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(models, mae_scores, color='green')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.title('Comparison of Mean Absolute Error (MAE) among Models using Location')\n",
    "# Add annotations to the bars\n",
    "for bar, mae in zip(bars, mae_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{mae:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot R-squared (R2)\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(models, r2_scores, color='orange')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('R-squared (R2)')\n",
    "plt.title('Comparison of R-squared (R2) among Models using Location')\n",
    "# Add annotations to the bars\n",
    "for bar, r2 in zip(bars, r2_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{r2:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91970f3f-75c2-4adc-a595-483645a4e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ardi_data = pd.read_csv(\"Cleaned_1_data.csv\")\n",
    "\n",
    "ardi_data\n",
    "\n",
    "# based on location Xgboost\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = [ 'AgeGroup','Sex', 'ConditionType', 'Category','Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on LocationAbbr using Linear Regression\n",
    "def predict_by_location_xgboost(location):\n",
    "    df_filtered = ardi_data[ardi_data['LocationAbbr'] == location]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['AgeGroup','Sex', 'ConditionType', 'Category','Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "       \n",
    "    model = XGBRegressor()  # Using XGBoost for regression\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    xgboost_mse = mean_squared_error(y_test, y_pred)\n",
    "    xgboost_mae = mean_absolute_error(y_test, y_pred)\n",
    "    xgboost_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, xgboost_mse, xgboost_mae, xgboost_r2\n",
    "\n",
    "# Example\n",
    "# Example prediction using Linear Regression based on LocationAbbr\n",
    "location = 'US'\n",
    "\n",
    "prediction, xgboost_mse, xgboost_mae, xgboost_r2 = predict_by_location_xgboost(location)\n",
    "print(f\"XGboost Predicted values for '{location}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", xgboost_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", xgboost_mae)\n",
    "print(\"R-squared (R2):\", xgboost_r2)\n",
    "\n",
    "# based on location SVR\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Load the dataset from ardi_data\n",
    "# df = pd.read_csv('ardi_data.csv')\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['AgeGroup','Sex', 'ConditionType', 'Category','Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on LocationAbbr using SVR\n",
    "def predict_by_location_svr(location):\n",
    "    df_filtered = ardi_data[ardi_data['LocationAbbr'] == location]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['AgeGroup','Sex', 'ConditionType', 'Category','Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    # model = SVR(kernel='linear')  # Using a linear kernel for SVR\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred = model.predict(X_test)\n",
    "    model = SVR(kernel='rbf')  # Using RBF kernel for SVR\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    svr_mse = mean_squared_error(y_test, y_pred)\n",
    "    svr_mae = mean_absolute_error(y_test, y_pred)\n",
    "    svr_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, svr_mse, svr_mae, svr_r2\n",
    "\n",
    "# Example prediction using SVR based on LocationAbbr\n",
    "location = 'US'\n",
    "\n",
    "prediction, svr_mse, svr_mae, svr_r2 = predict_by_location_svr(location)\n",
    "print(f\"SVR Predicted values for '{location}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", svr_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", svr_mae)\n",
    "print(\"R-squared (R2):\", svr_r2)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['AgeGroup', 'Sex', 'ConditionType', 'Category', 'Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on LocationAbbr using Random Forest\n",
    "def predict_by_location_random_forest(location):\n",
    "    df_filtered = ardi_data[ardi_data['LocationAbbr'] == location]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['AgeGroup', 'Sex', 'ConditionType', 'Category', 'Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RandomForestRegressor()  # Using RandomForestRegressor for regression\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    rf_mse = mean_squared_error(y_test, y_pred)\n",
    "    rf_mae = mean_absolute_error(y_test, y_pred)\n",
    "    rf_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, rf_mse, rf_mae, rf_r2\n",
    "\n",
    "# Example prediction using Random Forest based on LocationAbbr\n",
    "location = 'US'\n",
    "\n",
    "prediction, rf_mse, rf_mae, rf_r2 = predict_by_location_random_forest(location)\n",
    "print(f\"Random Forest Predicted values for '{location}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", rf_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", rf_mae)\n",
    "print(\"R-squared (R2):\", rf_r2)\n",
    "\n",
    "# Based on location linear\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = [ 'AgeGroup','Sex', 'ConditionType', 'Category','Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on LocationAbbr using Linear Regression\n",
    "def predict_by_location_linear(location):\n",
    "    df_filtered = ardi_data[ardi_data['LocationAbbr'] == location]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['AgeGroup','Sex', 'ConditionType', 'Category','Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    model = LinearRegression()  # Using Linear Regression\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "       \n",
    "    \n",
    "    linear_mse = mean_squared_error(y_test, y_pred)\n",
    "    linear_mae = mean_absolute_error(y_test, y_pred)\n",
    "    linear_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, linear_mse, linear_mae, linear_r2\n",
    "\n",
    "# Example\n",
    "# Example prediction using Linear Regression based on LocationAbbr\n",
    "location = 'US'\n",
    "\n",
    "prediction, linear_mse, linear_mae, linear_r2 = predict_by_location_linear(location)\n",
    "print(f\"Linear Regression Predicted values for '{location}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", linear_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", linear_mae)\n",
    "print(\"R-squared (R2):\", linear_r2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a list of model names and their respective metrics\n",
    "models = ['Linear Regression', 'XGBoost', 'SVR', 'RandomForest']\n",
    "mse_scores = [linear_mse, xgboost_mse, svr_mse, rf_mse]\n",
    "mae_scores = [linear_mae, xgboost_mae, svr_mae,rf_mae]\n",
    "r2_scores = [linear_r2, xgboost_r2, svr_r2,rf_r2]\n",
    "\n",
    "# Plot Mean Squared Error (MSE)\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(models, mse_scores, color='blue')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Comparison of Mean Squared Error (MSE) among Models using Location')\n",
    "\n",
    "# Add annotations to the bars\n",
    "for bar, mse in zip(bars, mse_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{mse:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot Mean Absolute Error (MAE)\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(models, mae_scores, color='green')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.title('Comparison of Mean Absolute Error (MAE) among Models using Location')\n",
    "# Add annotations to the bars\n",
    "for bar, mae in zip(bars, mae_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{mae:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot R-squared (R2)\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(models, r2_scores, color='orange')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('R-squared (R2)')\n",
    "plt.title('Comparison of R-squared (R2) among Models using Location')\n",
    "# Add annotations to the bars\n",
    "for bar, r2 in zip(bars, r2_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{r2:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b0af8-17ce-45af-9d8e-76bc117b61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sex\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "ardi_data = pd.read_csv(\"Cleaned_1_data.csv\")\n",
    "\n",
    "ardi_data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Load the dataset from ardi_data\n",
    "# df = pd.read_csv('ardi_data.csv')\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['AgeGroup','LocationAbbr', 'ConditionType', 'Category','Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on Sex using SVR\n",
    "def predict_by_sex_svr(sex):\n",
    "    df_filtered = ardi_data[ardi_data['Sex'] == sex]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['AgeGroup','LocationAbbr', 'ConditionType', 'Category','Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    model = SVR(kernel='linear')  # Using a linear kernel for SVR\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    linear_mse = mean_squared_error(y_test, y_pred)\n",
    "    linear_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    linear_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, linear_mse, linear_mae, linear_r2\n",
    "\n",
    "# Example prediction using SVR based on Sex\n",
    "sex = 'Male'\n",
    "\n",
    "prediction, linear_mse, linear_mae, linear_r2 = predict_by_sex_svr(sex)\n",
    "print(f\"SVR Predicted values for '{sex}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", linear_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", linear_mae)\n",
    "print(\"R-squared (R2):\", linear_r2)\n",
    "\n",
    "\n",
    "# based on location Xgboost\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['AgeGroup', 'LocationAbbr', 'ConditionType', 'Category', 'Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on LocationAbbr using XGBoost\n",
    "def predict_by_sex_xgboost(sex):\n",
    "    df_filtered = ardi_data[ardi_data['Sex'] == sex]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['AgeGroup', 'LocationAbbr', 'ConditionType', 'Category', 'Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = XGBRegressor()  # Using XGBoost for regression\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    xgboost_mse = mean_squared_error(y_test, y_pred)\n",
    "    xgboost_mae = mean_absolute_error(y_test, y_pred)\n",
    "    xgboost_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, xgboost_mse, xgboost_mae, xgboost_r2\n",
    "\n",
    "# Example prediction using XGBoost based on LocationAbbr\n",
    "sex = 'Male'\n",
    "\n",
    "prediction, xgboost_mse, xgboost_mae, xgboost_r2 = predict_by_sex_xgboost(sex)\n",
    "print(f\"XGBoost Predicted values for '{sex}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", xgboost_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", xgboost_mae)\n",
    "print(\"R-squared (R2):\", xgboost_r2)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor  # Import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['AgeGroup', 'LocationAbbr', 'ConditionType', 'Category', 'Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on LocationAbbr using Random Forest\n",
    "def predict_by_sex_random_forest(sex):\n",
    "    df_filtered = ardi_data[ardi_data['Sex'] == sex]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['AgeGroup', 'LocationAbbr', 'ConditionType', 'Category', 'Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RandomForestRegressor()  # Using RandomForestRegressor for regression\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    rf_mse = mean_squared_error(y_test, y_pred)\n",
    "    rf_mae = mean_absolute_error(y_test, y_pred)\n",
    "    rf_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, rf_mse, rf_mae, rf_r2\n",
    "\n",
    "# Example prediction using Random Forest based on LocationAbbr\n",
    "sex = 'Male'\n",
    "\n",
    "prediction, rf_mse, rf_mae, rf_r2 = predict_by_sex_random_forest(sex)\n",
    "print(f\"Random Forest Predicted values for '{sex}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", rf_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", rf_mae)\n",
    "print(\"R-squared (R2):\", rf_r2)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR  # Import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['AgeGroup', 'LocationAbbr', 'ConditionType', 'Category', 'Cause_of_Death']  # List of categorical columns to encode\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    ardi_data[col] = le.fit_transform(ardi_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Function to make predictions based on LocationAbbr using SVR\n",
    "def predict_by_sex_svr(sex):\n",
    "    df_filtered = ardi_data[ardi_data['Sex'] == sex]\n",
    "    \n",
    "    # Check if there are enough samples for splitting\n",
    "    if len(df_filtered) < 2:\n",
    "        raise ValueError(\"Insufficient samples for training and testing.\")\n",
    "    \n",
    "    X = df_filtered[['AgeGroup', 'LocationAbbr', 'ConditionType', 'Category', 'Cause_of_Death']]  # Features\n",
    "    y = df_filtered['Data_Value_Alt']  # Target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = SVR()  # Using SVR for regression\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    svr_mse = mean_squared_error(y_test, y_pred)\n",
    "    svr_mae = mean_absolute_error(y_test, y_pred)\n",
    "    svr_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, svr_mse, svr_mae, svr_r2\n",
    "\n",
    "# Example prediction using SVR based on LocationAbbr\n",
    "sex = 'Male'\n",
    "\n",
    "prediction, svr_mse, svr_mae, svr_r2 = predict_by_sex_svr(sex)\n",
    "print(f\"SVR Predicted values for '{sex}':\", prediction)\n",
    "print(\"Mean Squared Error (MSE):\", svr_mse)\n",
    "print(\"Mean Absolute Error (MAE):\", svr_mae)\n",
    "print(\"R-squared (R2):\", svr_r2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a list of model names and their respective metrics\n",
    "models = ['Linear Regression', 'XGBoost', 'SVR', 'RandomForest']\n",
    "mse_scores = [linear_mse, xgboost_mse, svr_mse, rf_mse]\n",
    "mae_scores = [linear_mae, xgboost_mae, svr_mae,rf_mae]\n",
    "r2_scores = [linear_r2, xgboost_r2, svr_r2,rf_r2]\n",
    "\n",
    "# Plot Mean Squared Error (MSE)\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(models, mse_scores, color='blue')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Comparison of Mean Squared Error (MSE) among Models using Location')\n",
    "\n",
    "# Add annotations to the bars\n",
    "for bar, mse in zip(bars, mse_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{mse:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot Mean Absolute Error (MAE)\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(models, mae_scores, color='green')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.title('Comparison of Mean Absolute Error (MAE) among Models using Location')\n",
    "# Add annotations to the bars\n",
    "for bar, mae in zip(bars, mae_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{mae:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot R-squared (R2)\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(models, r2_scores, color='orange')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('R-squared (R2)')\n",
    "plt.title('Comparison of R-squared (R2) among Models using Location')\n",
    "# Add annotations to the bars\n",
    "for bar, r2 in zip(bars, r2_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{r2:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de220627-bfe3-4ecb-a87f-d3ec8fa6101b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9fef9-6d15-41b7-bb28-5ce6a6d9870d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8cb0aa-70b5-4d53-919b-b45e2779d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## converted data preparation and exploartion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb81ea-0d6d-487a-bd55-6d0746e22b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "ardi_data = pd.read_csv('Alcohol-Related_Disease_Impact__ARDI__Application_-_Alcohol-Attributable_Deaths_20240217.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(ardi_data.head())\n",
    "\n",
    "# Display the shape of the DataFrame\n",
    "print(ardi_data.shape)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = ardi_data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Check for zero values in the 'Data_Value_Alt' column\n",
    "zero_values = ardi_data[ardi_data['Data_Value_Alt'] == 0]\n",
    "print(\"Rows with zero values:\")\n",
    "print(zero_values)\n",
    "\n",
    "# Check for negative values in the 'Data_Value_Alt' column\n",
    "negative_values = ardi_data[ardi_data['Data_Value_Alt'] < 0]\n",
    "print(\"Rows with negative values:\")\n",
    "print(negative_values)\n",
    "\n",
    "# Drop rows with negative values\n",
    "ardi_data = ardi_data[ardi_data['Data_Value_Alt'] >= 0]\n",
    "\n",
    "# Drop rows with empty cells (NaN or None) in the 'Data_Value_Alt' column\n",
    "ardi_data = ardi_data.dropna(subset=['Data_Value_Alt'])\n",
    "\n",
    "# Convert 'YearStart' and 'YearEnd' to years only\n",
    "ardi_data['YearStart'] = pd.to_datetime(ardi_data['YearStart'], format='%Y').dt.year\n",
    "ardi_data['YearEnd'] = pd.to_datetime(ardi_data['YearEnd'], format='%Y').dt.year\n",
    "\n",
    "# Map age groups to categories\n",
    "age_group_mapping = {\n",
    "    'Under 21': 'Under 21',\n",
    "    '0-19': 'Under 21',\n",
    "    '20-34': '21-34',\n",
    "    '35-49': '35-49',\n",
    "    '50-64': '50-64',\n",
    "    '65+': '65 and older',\n",
    "    'Overall': 'Overall'\n",
    "}\n",
    "ardi_data['AgeGroup_Cat'] = ardi_data['AgeGroup'].map(age_group_mapping)\n",
    "\n",
    "# Drop unnecessary columns and rows\n",
    "ardi_data_cleaned = ardi_data[['YearStart', 'YearEnd', 'LocationAbbr', 'LocationDesc', 'DataSource', 'ConditionType',\n",
    "                               'Category', 'Cause_of_Death', 'Effect', 'ConsumptionPattern', 'Sex', 'AgeGroup',\n",
    "                               'AgeGroup_Cat']]\n",
    "ardi_data_cleaned = ardi_data_cleaned[ardi_data_cleaned['LocationDesc'] != 'United States']\n",
    "\n",
    "# Save cleaned data to a new CSV file\n",
    "ardi_data_cleaned.to_csv(\"Cleaned_1_data.csv\", index=False)\n",
    "\n",
    "# Log transformation for right-skewed data\n",
    "transformed_data = np.log(ardi_data_cleaned['Data_Value_Alt'])\n",
    "\n",
    "# Plot boxplots for original and transformed data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([ardi_data_cleaned['Data_Value_Alt'], transformed_data], labels=['Original Data', 'Transformed Data (Log Scale)'])\n",
    "plt.title('Effect of Log Transformation')\n",
    "plt.ylabel('Data Value')\n",
    "plt.show()\n",
    "\n",
    "# Total number of deaths by sex\n",
    "total_deaths_by_sex = ardi_data_cleaned.groupby('Sex')['Data_Value_Alt'].sum()\n",
    "\n",
    "# Pie chart for total number of deaths by sex\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(total_deaths_by_sex, labels=total_deaths_by_sex.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Total Number of Deaths by Sex (2015-2019)')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Total number of deaths by condition type\n",
    "total_deaths_by_type = ardi_data_cleaned.groupby('ConditionType')['Data_Value_Alt'].sum().reset_index()\n",
    "\n",
    "# Bar plot for number of deaths by condition\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='ConditionType', y='Data_Value_Alt', data=total_deaths_by_type, palette='viridis')\n",
    "plt.title('Number of Deaths by Condition for United States')\n",
    "plt.xlabel('Condition Type')\n",
    "plt.ylabel('Number of Deaths')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "for i, (condition, total) in enumerate(zip(total_deaths_by_type['ConditionType'], total_deaths_by_type['Data_Value_Alt'])):\n",
    "    plt.text(i, total + 10, str(round(total, 2)), ha='center', va='bottom', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Total number of deaths by state\n",
    "deaths_by_state = ardi_data_cleaned.groupby('LocationDesc')['Data_Value_Alt'].sum().reset_index()\n",
    "deaths_by_state = deaths_by_state[deaths_by_state['LocationDesc'] != 'United States']\n",
    "deaths_by_state = deaths_by_state.sort_values(by='Data_Value_Alt', ascending=False)\n",
    "\n",
    "# Bar plot for number of deaths by state\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='LocationDesc', y='Data_Value_Alt', data=deaths_by_state, palette='viridis')\n",
    "plt.title('Number of Deaths by State for United States')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Deaths')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "for i in range(0, len(deaths_by_state), 2):\n",
    "    plt.text(i, deaths_by_state.iloc[i]['Data_Value_Alt'] + 10, str(deaths_by_state.iloc[i]['Data_Value_Alt']), ha='center', va='bottom', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89cd4b-c265-4b40-8cc2-7a3f8a23255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing necessary libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# ardi_data = pd.read_csv('Alcohol-Related_Disease_Impact__ARDI__Application_-_Alcohol-Attributable_Deaths_20240217.csv')\n",
    "\n",
    "# # Display the first few rows of the DataFrame\n",
    "# print(ardi_data.head())\n",
    "\n",
    "# # Display the shape of the DataFrame\n",
    "# print(ardi_data.shape)\n",
    "\n",
    "# # Check for missing values\n",
    "# missing_values = ardi_data.isnull().sum()\n",
    "# print(missing_values)\n",
    "\n",
    "# # Check for zero values in the 'Data_Value_Alt' column\n",
    "# zero_values = ardi_data[ardi_data['Data_Value_Alt'] == 0]\n",
    "# print(\"Rows with zero values:\")\n",
    "# print(zero_values)\n",
    "\n",
    "# # Check for negative values in the 'Data_Value_Alt' column\n",
    "# negative_values = ardi_data[ardi_data['Data_Value_Alt'] < 0]\n",
    "# print(\"Rows with negative values:\")\n",
    "# print(negative_values)\n",
    "\n",
    "# # Drop rows with negative values\n",
    "# ardi_data = ardi_data[ardi_data['Data_Value_Alt'] >= 0]\n",
    "\n",
    "# # Drop rows with empty cells (NaN or None) in the 'Data_Value_Alt' column\n",
    "# ardi_data = ardi_data.dropna(subset=['Data_Value_Alt'])\n",
    "\n",
    "# # Convert 'YearStart' and 'YearEnd' to years only\n",
    "# ardi_data['YearStart'] = pd.to_datetime(ardi_data['YearStart'], format='%Y').dt.year\n",
    "# ardi_data['YearEnd'] = pd.to_datetime(ardi_data['YearEnd'], format='%Y').dt.year\n",
    "\n",
    "# # Map age groups to categories\n",
    "# age_group_mapping = {\n",
    "#     'Under 21': 'Under 21',\n",
    "#     '0-19': 'Under 21',\n",
    "#     '20-34': '21-34',\n",
    "#     '35-49': '35-49',\n",
    "#     '50-64': '50-64',\n",
    "#     '65+': '65 and older',\n",
    "#     'Overall': 'Overall'\n",
    "# }\n",
    "# ardi_data['AgeGroup_Cat'] = ardi_data['AgeGroup'].map(age_group_mapping)\n",
    "\n",
    "# # Drop unnecessary columns and rows\n",
    "# ardi_data_cleaned = ardi_data[['YearStart', 'YearEnd', 'LocationAbbr', 'LocationDesc', 'DataSource', 'ConditionType',\n",
    "#                                'Category', 'Cause_of_Death', 'Effect', 'ConsumptionPattern', 'Sex', 'AgeGroup',\n",
    "#                                'AgeGroup_Cat']]\n",
    "# ardi_data_cleaned = ardi_data_cleaned[ardi_data_cleaned['LocationDesc'] != 'United States']\n",
    "\n",
    "# # Save cleaned data to a new CSV file\n",
    "# ardi_data_cleaned.to_csv(\"Cleaned_1_data.csv\", index=False)\n",
    "\n",
    "# # Log transformation for right-skewed data\n",
    "# transformed_data = np.log(ardi_data_cleaned['Data_Value_Alt'])\n",
    "\n",
    "# # Plot boxplots for original and transformed data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.boxplot([ardi_data_cleaned['Data_Value_Alt'], transformed_data], labels=['Original Data', 'Transformed Data (Log Scale)'])\n",
    "# plt.title('Effect of Log Transformation')\n",
    "# plt.ylabel('Data Value')\n",
    "# plt.show()\n",
    "\n",
    "# # Total number of deaths by sex\n",
    "# total_deaths_by_sex = ardi_data_cleaned.groupby('Sex')['Data_Value_Alt'].sum()\n",
    "\n",
    "# # Pie chart for total number of deaths by sex\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.pie(total_deaths_by_sex, labels=total_deaths_by_sex.index, autopct='%1.1f%%', startangle=140)\n",
    "# plt.title('Total Number of Deaths by Sex (2015-2019)')\n",
    "# plt.axis('equal')\n",
    "# plt.show()\n",
    "\n",
    "# # Total number of deaths by condition type\n",
    "# total_deaths_by_type = ardi_data_cleaned.groupby('ConditionType')['Data_Value_Alt'].sum().reset_index()\n",
    "\n",
    "# # Bar plot for number of deaths by condition\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.barplot(x='ConditionType', y='Data_Value_Alt', data=total_deaths_by_type, palette='viridis')\n",
    "# plt.title('Number of Deaths by Condition for United States')\n",
    "# plt.xlabel('Condition Type')\n",
    "# plt.ylabel('Number of Deaths')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# for i, (condition, total) in enumerate(zip(total_deaths_by_type['ConditionType'], total_deaths_by_type['Data_Value_Alt'])):\n",
    "#     plt.text(i, total + 10, str(round(total, 2)), ha='center', va='bottom', rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Total number of deaths by state\n",
    "# deaths_by_state = ardi_data_cleaned.groupby('LocationDesc')['Data_Value_Alt'].sum().reset_index()\n",
    "# deaths_by_state = deaths_by_state[deaths_by_state['LocationDesc'] != 'United States']\n",
    "# deaths_by_state = deaths_by_state.sort_values(by='Data_Value_Alt', ascending=False)\n",
    "\n",
    "# # Bar plot for number of deaths by state\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.barplot(x='LocationDesc', y='Data_Value_Alt', data=deaths_by_state, palette='viridis')\n",
    "# plt.title('Number of Deaths by State for United States')\n",
    "# plt.xlabel('State')\n",
    "# plt.ylabel('Number of Deaths')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# for i in range(0, len(deaths_by_state), 2):\n",
    "#     plt.text(i, deaths_by_state.iloc[i]['Data_Value_Alt'] + 10, str(deaths_by_state.iloc[i]['Data_Value_Alt']), ha='center', va='bottom', rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Violin Plot for Distribution of Deaths by State\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.violinplot(x='LocationDesc', y='Data_Value_Alt', data=ardi_data_cleaned, palette='viridis')\n",
    "# plt.title('Distribution of Deaths by State (Violin Plot)')\n",
    "# plt.xlabel('State')\n",
    "# plt.ylabel('Number of Deaths')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Frequency count of 'Sex' categorical variable (bar chart) with annotation\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# counts = ardi_data_cleaned['Sex'].value_counts()\n",
    "# counts.plot(kind='bar')\n",
    "# plt.title('Distribution of Sex in the data ')\n",
    "# plt.xlabel('Sex')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.xticks(rotation=45)\n",
    "# for i, count in enumerate(counts):\n",
    "#     plt.text(i, count + 10, str(count), ha='center', va='bottom')\n",
    "\n",
    "# # Bar Chart for Frequency Count of 'LocationDesc'\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# ardi_data_cleaned['LocationAbbr'].value_counts().plot(kind='bar')\n",
    "# plt.title('Frequency Count of LocationDesc')\n",
    "# plt.xlabel('LocationDesc')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# # Frequency count of 'AgeGroup_Cat' categorical variable (bar chart) with annotation\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# counts = ardi_data_cleaned['AgeGroup_Cat'].value_counts()\n",
    "# counts.plot(kind='bar')\n",
    "# plt.title('Distribution of AgeCategory')\n",
    "# plt.xlabel('AgeCategory')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.xticks(rotation=45)\n",
    "# for i, count in enumerate(counts):\n",
    "#     plt.text(i, count + 10, str(count), ha='center', va='bottom')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Density Plot for 'Data_Value_Alt' grouped by 'Sex'\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.kdeplot(data=ardi_data_cleaned, x='Data_Value_Alt', hue='Sex', fill=True)\n",
    "# plt.title('Density Plot of Data_Value_Alt by Sex')\n",
    "# plt.xlabel('Data_Value_Alt')\n",
    "# plt.ylabel('Density')\n",
    "# plt.show()\n",
    "\n",
    "# # K-means Clustering\n",
    "# cluster_data = ardi_data_cleaned[['LocationDesc', 'Data_Value_Alt']].copy()\n",
    "# scaler = StandardScaler()\n",
    "# normalized_data = scaler.fit_transform(cluster_data[['Data_Value_Alt']])\n",
    "# kmeans = KMeans(n_clusters=5)\n",
    "# kmeans.fit(normalized_data)\n",
    "# cluster_data['Cluster'] = kmeans.labels_\n",
    "# cluster_data.to_csv('clustered_data.csv', index=False)\n",
    "\n",
    "# # Encoding Categorical Variables\n",
    "# label_encoders = {}\n",
    "# categorical_columns = ['LocationAbbr', 'LocationDesc', 'DataSource', 'ConditionType', 'Category', 'Cause_of_Death',\n",
    "#                        'Effect', 'ConsumptionPattern', 'Sex', 'AgeGroup_Cat', 'AgeGroup']\n",
    "\n",
    "# for col in categorical_columns:\n",
    "#     le = LabelEncoder()\n",
    "#     ardi_data_cleaned[col] = le.fit_transform(ardi_data_cleaned[col].astype(str))\n",
    "#     label_encoders[col] = le\n",
    "\n",
    "# X = ardi_data_cleaned.drop(['Data_Value_Alt'], axis=1)\n",
    "# y = ardi_data_cleaned['Data_Value_Alt']\n",
    "\n",
    "# # Splitting Data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # RandomForestRegressor for Feature Importance\n",
    "# rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "\n",
    "# importances = rf_model.feature_importances_\n",
    "# features = X.columns\n",
    "\n",
    "# # Plotting Feature Importances\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.barplot(x=importances, y=features)\n",
    "# plt.title('Feature Importance')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Correlation Matrix\n",
    "# ardi_data_cleaned_numeric = ardi_data_cleaned.drop(columns=['DataSource', 'Effect'])\n",
    "# corr_matrix = ardi_data_cleaned_numeric.corr()\n",
    "\n",
    "# # Heatmap of correlation matrix\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(corr_matrix, annot=True, fmt=\".2f\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
